{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_d3_armnet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ondlVTwwgTII",
        "outputId": "85f704d4-0d8d-4378-be80-301825b9ae80"
      },
      "source": [
        "from google.colab import drive\n",
        "#drive.flush_and_unmount()\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djYWKuJdhWXK"
      },
      "source": [
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn.modules.module import Module\n",
        "from torch import Tensor\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chNwcw_LhkyS"
      },
      "source": [
        "## Read mobility files / NOS of days of data\n",
        "%cd /content/gdrive/My Drive/Mobility_data/\n",
        "mobility_csv_files = glob.glob(\"*.csv\")\n",
        "print (mobility_csv_files)\n",
        "print (len(mobility_csv_files)) # Nos of days\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWdkYaHdGCtJ"
      },
      "source": [
        "# create a date range to keep track of the sequence of the days while reading mobility data files for each day\n",
        "import datetime\n",
        "start_date = datetime.date(2020, 5, 12)\n",
        "number_of_days = 235\n",
        "\n",
        "date_list = []\n",
        "for day in range(number_of_days):\n",
        "  a_date = (start_date + datetime.timedelta(days = day)).isoformat() + \"-social-distancing.csv.mobility.csv\"\n",
        "  date_list.append(a_date)\n",
        "\n",
        "#print(date_list)\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "FKYEiDTqCtfe",
        "outputId": "dc207122-5ec2-4f97-e931-fa33cd1a9893"
      },
      "source": [
        "# Predictor Z\n",
        "deaths_data = pd.read_csv ('/content/gdrive/My Drive/DeepAR-pytorch-master/data/elect/COUNTY_DEATHS_DATA.csv')\n",
        "deaths_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Days</th>\n",
              "      <th>Autauga</th>\n",
              "      <th>Baldwin</th>\n",
              "      <th>Barbour</th>\n",
              "      <th>Bibb</th>\n",
              "      <th>Blount</th>\n",
              "      <th>Bullock</th>\n",
              "      <th>Butler</th>\n",
              "      <th>Calhoun</th>\n",
              "      <th>Chambers</th>\n",
              "      <th>Cherokee</th>\n",
              "      <th>Chilton</th>\n",
              "      <th>Choctaw</th>\n",
              "      <th>Clarke</th>\n",
              "      <th>Clay</th>\n",
              "      <th>Coffee</th>\n",
              "      <th>Colbert</th>\n",
              "      <th>Conecuh</th>\n",
              "      <th>Coosa</th>\n",
              "      <th>Covington</th>\n",
              "      <th>Crenshaw</th>\n",
              "      <th>Cullman</th>\n",
              "      <th>Dale</th>\n",
              "      <th>Dallas</th>\n",
              "      <th>DeKalb</th>\n",
              "      <th>Elmore</th>\n",
              "      <th>Escambia</th>\n",
              "      <th>Etowah</th>\n",
              "      <th>Fayette</th>\n",
              "      <th>Franklin</th>\n",
              "      <th>Geneva</th>\n",
              "      <th>Greene</th>\n",
              "      <th>Hale</th>\n",
              "      <th>Henry</th>\n",
              "      <th>Houston</th>\n",
              "      <th>Jackson</th>\n",
              "      <th>Jefferson</th>\n",
              "      <th>Lamar</th>\n",
              "      <th>Lauderdale</th>\n",
              "      <th>Lawrence</th>\n",
              "      <th>...</th>\n",
              "      <th>Custer</th>\n",
              "      <th>Delta</th>\n",
              "      <th>Denver</th>\n",
              "      <th>Douglas</th>\n",
              "      <th>Eagle</th>\n",
              "      <th>El Paso</th>\n",
              "      <th>Elbert</th>\n",
              "      <th>Fremont</th>\n",
              "      <th>Garfield</th>\n",
              "      <th>Gilpin</th>\n",
              "      <th>Grand</th>\n",
              "      <th>Gunnison</th>\n",
              "      <th>Hinsdale</th>\n",
              "      <th>Huerfano</th>\n",
              "      <th>Jackson.2</th>\n",
              "      <th>Jefferson.2</th>\n",
              "      <th>Kiowa</th>\n",
              "      <th>Kit Carson</th>\n",
              "      <th>La Plata</th>\n",
              "      <th>Lake.1</th>\n",
              "      <th>Larimer</th>\n",
              "      <th>Las Animas</th>\n",
              "      <th>Lincoln.1</th>\n",
              "      <th>Logan.1</th>\n",
              "      <th>Mesa</th>\n",
              "      <th>Mineral</th>\n",
              "      <th>Moffat</th>\n",
              "      <th>Montezuma</th>\n",
              "      <th>Montrose</th>\n",
              "      <th>Morgan.1</th>\n",
              "      <th>Otero</th>\n",
              "      <th>Ouray</th>\n",
              "      <th>Park</th>\n",
              "      <th>Phillips.1</th>\n",
              "      <th>Pitkin</th>\n",
              "      <th>Prowers</th>\n",
              "      <th>Pueblo</th>\n",
              "      <th>Rio Blanco</th>\n",
              "      <th>Routt</th>\n",
              "      <th>Saguache</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5/12/2020</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>22</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>6</td>\n",
              "      <td>20</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>248</td>\n",
              "      <td>15</td>\n",
              "      <td>8</td>\n",
              "      <td>83</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5/13/2020</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>22</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>261</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>83</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>150</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5/14/2020</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>10</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>22</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>265</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>83</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>150</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5/15/2020</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>18</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>10</td>\n",
              "      <td>12</td>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>10</td>\n",
              "      <td>430</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>272</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>83</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>430</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>150</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5/16/2020</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>21</td>\n",
              "      <td>10</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>285</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>12/22/2020</td>\n",
              "      <td>47</td>\n",
              "      <td>75</td>\n",
              "      <td>32</td>\n",
              "      <td>257</td>\n",
              "      <td>58</td>\n",
              "      <td>20</td>\n",
              "      <td>45</td>\n",
              "      <td>4</td>\n",
              "      <td>61</td>\n",
              "      <td>130</td>\n",
              "      <td>54</td>\n",
              "      <td>22</td>\n",
              "      <td>65</td>\n",
              "      <td>30</td>\n",
              "      <td>87</td>\n",
              "      <td>59</td>\n",
              "      <td>17</td>\n",
              "      <td>7</td>\n",
              "      <td>38</td>\n",
              "      <td>36</td>\n",
              "      <td>76</td>\n",
              "      <td>63</td>\n",
              "      <td>10</td>\n",
              "      <td>54</td>\n",
              "      <td>9</td>\n",
              "      <td>360</td>\n",
              "      <td>91</td>\n",
              "      <td>43</td>\n",
              "      <td>29</td>\n",
              "      <td>18</td>\n",
              "      <td>58</td>\n",
              "      <td>33</td>\n",
              "      <td>53</td>\n",
              "      <td>123</td>\n",
              "      <td>43</td>\n",
              "      <td>35</td>\n",
              "      <td>31</td>\n",
              "      <td>68</td>\n",
              "      <td>27</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>662</td>\n",
              "      <td>27</td>\n",
              "      <td>14</td>\n",
              "      <td>535</td>\n",
              "      <td>34</td>\n",
              "      <td>13</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>43</td>\n",
              "      <td>35</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>29</td>\n",
              "      <td>797</td>\n",
              "      <td>128</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>47</td>\n",
              "      <td>127</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>14</td>\n",
              "      <td>29</td>\n",
              "      <td>81</td>\n",
              "      <td>35</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>20</td>\n",
              "      <td>297</td>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225</th>\n",
              "      <td>12/23/2020</td>\n",
              "      <td>47</td>\n",
              "      <td>75</td>\n",
              "      <td>32</td>\n",
              "      <td>257</td>\n",
              "      <td>58</td>\n",
              "      <td>20</td>\n",
              "      <td>45</td>\n",
              "      <td>4</td>\n",
              "      <td>61</td>\n",
              "      <td>130</td>\n",
              "      <td>54</td>\n",
              "      <td>22</td>\n",
              "      <td>65</td>\n",
              "      <td>30</td>\n",
              "      <td>87</td>\n",
              "      <td>59</td>\n",
              "      <td>17</td>\n",
              "      <td>7</td>\n",
              "      <td>38</td>\n",
              "      <td>36</td>\n",
              "      <td>76</td>\n",
              "      <td>63</td>\n",
              "      <td>11</td>\n",
              "      <td>58</td>\n",
              "      <td>9</td>\n",
              "      <td>367</td>\n",
              "      <td>90</td>\n",
              "      <td>43</td>\n",
              "      <td>29</td>\n",
              "      <td>18</td>\n",
              "      <td>59</td>\n",
              "      <td>33</td>\n",
              "      <td>53</td>\n",
              "      <td>125</td>\n",
              "      <td>44</td>\n",
              "      <td>35</td>\n",
              "      <td>31</td>\n",
              "      <td>68</td>\n",
              "      <td>27</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>667</td>\n",
              "      <td>27</td>\n",
              "      <td>15</td>\n",
              "      <td>543</td>\n",
              "      <td>34</td>\n",
              "      <td>13</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>44</td>\n",
              "      <td>35</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>29</td>\n",
              "      <td>802</td>\n",
              "      <td>134</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>48</td>\n",
              "      <td>129</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>15</td>\n",
              "      <td>30</td>\n",
              "      <td>82</td>\n",
              "      <td>36</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>20</td>\n",
              "      <td>300</td>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226</th>\n",
              "      <td>12/24/2020</td>\n",
              "      <td>48</td>\n",
              "      <td>75</td>\n",
              "      <td>32</td>\n",
              "      <td>259</td>\n",
              "      <td>63</td>\n",
              "      <td>20</td>\n",
              "      <td>45</td>\n",
              "      <td>4</td>\n",
              "      <td>62</td>\n",
              "      <td>130</td>\n",
              "      <td>54</td>\n",
              "      <td>22</td>\n",
              "      <td>65</td>\n",
              "      <td>30</td>\n",
              "      <td>91</td>\n",
              "      <td>60</td>\n",
              "      <td>17</td>\n",
              "      <td>7</td>\n",
              "      <td>38</td>\n",
              "      <td>36</td>\n",
              "      <td>76</td>\n",
              "      <td>63</td>\n",
              "      <td>11</td>\n",
              "      <td>59</td>\n",
              "      <td>9</td>\n",
              "      <td>372</td>\n",
              "      <td>90</td>\n",
              "      <td>43</td>\n",
              "      <td>29</td>\n",
              "      <td>18</td>\n",
              "      <td>59</td>\n",
              "      <td>33</td>\n",
              "      <td>54</td>\n",
              "      <td>125</td>\n",
              "      <td>44</td>\n",
              "      <td>35</td>\n",
              "      <td>32</td>\n",
              "      <td>69</td>\n",
              "      <td>27</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>672</td>\n",
              "      <td>28</td>\n",
              "      <td>15</td>\n",
              "      <td>551</td>\n",
              "      <td>34</td>\n",
              "      <td>14</td>\n",
              "      <td>28</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>44</td>\n",
              "      <td>35</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>28</td>\n",
              "      <td>812</td>\n",
              "      <td>137</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>49</td>\n",
              "      <td>132</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>15</td>\n",
              "      <td>30</td>\n",
              "      <td>82</td>\n",
              "      <td>39</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>20</td>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>12/25/2020</td>\n",
              "      <td>48</td>\n",
              "      <td>75</td>\n",
              "      <td>32</td>\n",
              "      <td>261</td>\n",
              "      <td>63</td>\n",
              "      <td>22</td>\n",
              "      <td>45</td>\n",
              "      <td>4</td>\n",
              "      <td>63</td>\n",
              "      <td>132</td>\n",
              "      <td>54</td>\n",
              "      <td>22</td>\n",
              "      <td>66</td>\n",
              "      <td>30</td>\n",
              "      <td>93</td>\n",
              "      <td>60</td>\n",
              "      <td>17</td>\n",
              "      <td>7</td>\n",
              "      <td>40</td>\n",
              "      <td>36</td>\n",
              "      <td>78</td>\n",
              "      <td>63</td>\n",
              "      <td>11</td>\n",
              "      <td>62</td>\n",
              "      <td>9</td>\n",
              "      <td>373</td>\n",
              "      <td>94</td>\n",
              "      <td>43</td>\n",
              "      <td>29</td>\n",
              "      <td>20</td>\n",
              "      <td>59</td>\n",
              "      <td>33</td>\n",
              "      <td>55</td>\n",
              "      <td>130</td>\n",
              "      <td>44</td>\n",
              "      <td>36</td>\n",
              "      <td>32</td>\n",
              "      <td>70</td>\n",
              "      <td>27</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>674</td>\n",
              "      <td>28</td>\n",
              "      <td>16</td>\n",
              "      <td>555</td>\n",
              "      <td>33</td>\n",
              "      <td>14</td>\n",
              "      <td>28</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>44</td>\n",
              "      <td>36</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>28</td>\n",
              "      <td>818</td>\n",
              "      <td>142</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>51</td>\n",
              "      <td>134</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>16</td>\n",
              "      <td>31</td>\n",
              "      <td>82</td>\n",
              "      <td>39</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>304</td>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>12/26/2020</td>\n",
              "      <td>48</td>\n",
              "      <td>75</td>\n",
              "      <td>9</td>\n",
              "      <td>261</td>\n",
              "      <td>98</td>\n",
              "      <td>22</td>\n",
              "      <td>194</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>72</td>\n",
              "      <td>54</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>65</td>\n",
              "      <td>60</td>\n",
              "      <td>17</td>\n",
              "      <td>7</td>\n",
              "      <td>67</td>\n",
              "      <td>36</td>\n",
              "      <td>78</td>\n",
              "      <td>63</td>\n",
              "      <td>2007</td>\n",
              "      <td>33</td>\n",
              "      <td>9</td>\n",
              "      <td>373</td>\n",
              "      <td>94</td>\n",
              "      <td>48</td>\n",
              "      <td>83</td>\n",
              "      <td>20</td>\n",
              "      <td>4</td>\n",
              "      <td>124</td>\n",
              "      <td>53</td>\n",
              "      <td>23</td>\n",
              "      <td>18</td>\n",
              "      <td>61</td>\n",
              "      <td>95</td>\n",
              "      <td>28</td>\n",
              "      <td>58</td>\n",
              "      <td>...</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>674</td>\n",
              "      <td>30</td>\n",
              "      <td>16</td>\n",
              "      <td>1666</td>\n",
              "      <td>33</td>\n",
              "      <td>64</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>18</td>\n",
              "      <td>61</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>28</td>\n",
              "      <td>13</td>\n",
              "      <td>142</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "      <td>58</td>\n",
              "      <td>134</td>\n",
              "      <td>62</td>\n",
              "      <td>19</td>\n",
              "      <td>16</td>\n",
              "      <td>31</td>\n",
              "      <td>8</td>\n",
              "      <td>38</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>304</td>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>229 rows × 278 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Days  Autauga  Baldwin  Barbour  ...  Pueblo  Rio Blanco  Routt  Saguache\n",
              "0     5/12/2020        4       12        1  ...      13           0      6         0\n",
              "1     5/13/2020        4       12        1  ...      13           0      6         0\n",
              "2     5/14/2020        4       14        1  ...      13           0      6         0\n",
              "3     5/15/2020        4       14        1  ...      14           0      6         0\n",
              "4     5/16/2020        4       14        1  ...      14           0      6         0\n",
              "..          ...      ...      ...      ...  ...     ...         ...    ...       ...\n",
              "224  12/22/2020       47       75       32  ...     297           2     18         4\n",
              "225  12/23/2020       47       75       32  ...     300           2     18         4\n",
              "226  12/24/2020       48       75       32  ...     302           3     18         4\n",
              "227  12/25/2020       48       75       32  ...     304           3     18         4\n",
              "228  12/26/2020       48       75        9  ...     304           3     18         4\n",
              "\n",
              "[229 rows x 278 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqxNkz7ohpDv"
      },
      "source": [
        "#census data - as a reference for keeping the same counties in NYT covid data and Safegraph mobility data\n",
        "census_df = pd.read_csv('/content/gdrive/My Drive/nodes.csv')\n",
        "census_df.drop(census_df.iloc[:, 0:1], inplace = True, axis = 1)\n",
        "#census_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwnFv9RKpTel"
      },
      "source": [
        "drop_counties = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZtyvr4Rh1aK"
      },
      "source": [
        "# Get COLUMN names for matching the counties of mobility and NYT COVID CASES/DEATHS data\n",
        "census_df = census_df.iloc[0:300,:] # take  first 300 counties\n",
        "column_name = census_df[\"origin_county_FIPS\"].tolist()\n",
        "\n",
        "# Drop those counties for creating mobility data  which are also dropped from NYT COVID data ## missing values\n",
        "drop_counties = [1029,2013,2016,2060,2068,2100,2164,2185,2164,2188,2232,2280,4023,5081,6035,6049,8033,8105]\n",
        "for counties in drop_counties:\n",
        "  if counties in column_name:\n",
        "    column_name.remove(counties)\n",
        "\n",
        "column_name = column_name[:277]\n",
        "\n",
        "# column_name\n",
        "# len(column_name[:277])\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "N751O_ysBP6Y",
        "outputId": "acddf601-bd46-408d-d107-5ec0e8151bb3"
      },
      "source": [
        "# Predictor Z ## Nos of cases\n",
        "cases_data_df = pd.read_csv(\"/content/gdrive/My Drive/DeepAR-pytorch-master/data/elect/COUNTY_CASES_DATA.csv\")\n",
        "cases_data_df = cases_data_df.iloc[:,1:]\n",
        "cases_data_df\n",
        "# cases_data_df.T"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>190</th>\n",
              "      <th>191</th>\n",
              "      <th>192</th>\n",
              "      <th>193</th>\n",
              "      <th>194</th>\n",
              "      <th>195</th>\n",
              "      <th>196</th>\n",
              "      <th>197</th>\n",
              "      <th>198</th>\n",
              "      <th>199</th>\n",
              "      <th>200</th>\n",
              "      <th>201</th>\n",
              "      <th>202</th>\n",
              "      <th>203</th>\n",
              "      <th>204</th>\n",
              "      <th>205</th>\n",
              "      <th>206</th>\n",
              "      <th>207</th>\n",
              "      <th>208</th>\n",
              "      <th>209</th>\n",
              "      <th>210</th>\n",
              "      <th>211</th>\n",
              "      <th>212</th>\n",
              "      <th>213</th>\n",
              "      <th>214</th>\n",
              "      <th>215</th>\n",
              "      <th>216</th>\n",
              "      <th>217</th>\n",
              "      <th>218</th>\n",
              "      <th>219</th>\n",
              "      <th>220</th>\n",
              "      <th>221</th>\n",
              "      <th>222</th>\n",
              "      <th>223</th>\n",
              "      <th>224</th>\n",
              "      <th>225</th>\n",
              "      <th>226</th>\n",
              "      <th>227</th>\n",
              "      <th>228</th>\n",
              "      <th>229</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Autauga</th>\n",
              "      <td>104.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>147.0</td>\n",
              "      <td>149.0</td>\n",
              "      <td>155.0</td>\n",
              "      <td>159.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>189.0</td>\n",
              "      <td>205.0</td>\n",
              "      <td>212.0</td>\n",
              "      <td>216.0</td>\n",
              "      <td>221.0</td>\n",
              "      <td>234.0</td>\n",
              "      <td>240.0</td>\n",
              "      <td>240.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>249.0</td>\n",
              "      <td>260.0</td>\n",
              "      <td>266.0</td>\n",
              "      <td>273.0</td>\n",
              "      <td>283.0</td>\n",
              "      <td>296.0</td>\n",
              "      <td>316.0</td>\n",
              "      <td>327.0</td>\n",
              "      <td>335.0</td>\n",
              "      <td>361.0</td>\n",
              "      <td>368.0</td>\n",
              "      <td>373.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>411.0</td>\n",
              "      <td>431.0</td>\n",
              "      <td>434.0</td>\n",
              "      <td>442.0</td>\n",
              "      <td>453.0</td>\n",
              "      <td>469.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2634.0</td>\n",
              "      <td>2661.0</td>\n",
              "      <td>2686.0</td>\n",
              "      <td>2704.0</td>\n",
              "      <td>2716.0</td>\n",
              "      <td>2735.0</td>\n",
              "      <td>2751.0</td>\n",
              "      <td>2780.0</td>\n",
              "      <td>2818.0</td>\n",
              "      <td>2873.0</td>\n",
              "      <td>2893.0</td>\n",
              "      <td>2945.0</td>\n",
              "      <td>2979.0</td>\n",
              "      <td>3005.0</td>\n",
              "      <td>3043.0</td>\n",
              "      <td>3087.0</td>\n",
              "      <td>3117.0</td>\n",
              "      <td>3186.0</td>\n",
              "      <td>3233.0</td>\n",
              "      <td>3258.0</td>\n",
              "      <td>3300.0</td>\n",
              "      <td>3329.0</td>\n",
              "      <td>3426.0</td>\n",
              "      <td>3510.0</td>\n",
              "      <td>3570.0</td>\n",
              "      <td>3647.0</td>\n",
              "      <td>3698.0</td>\n",
              "      <td>3741.0</td>\n",
              "      <td>3780.0</td>\n",
              "      <td>3841.0</td>\n",
              "      <td>3889.0</td>\n",
              "      <td>3942.0</td>\n",
              "      <td>3990.0</td>\n",
              "      <td>3999.0</td>\n",
              "      <td>4029.0</td>\n",
              "      <td>4065.0</td>\n",
              "      <td>4105.0</td>\n",
              "      <td>4164.0</td>\n",
              "      <td>4190.0</td>\n",
              "      <td>48.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Baldwin</th>\n",
              "      <td>243.0</td>\n",
              "      <td>282.0</td>\n",
              "      <td>284.0</td>\n",
              "      <td>287.0</td>\n",
              "      <td>290.0</td>\n",
              "      <td>292.0</td>\n",
              "      <td>296.0</td>\n",
              "      <td>299.0</td>\n",
              "      <td>329.0</td>\n",
              "      <td>329.0</td>\n",
              "      <td>331.0</td>\n",
              "      <td>330.0</td>\n",
              "      <td>335.0</td>\n",
              "      <td>281.0</td>\n",
              "      <td>282.0</td>\n",
              "      <td>343.0</td>\n",
              "      <td>345.0</td>\n",
              "      <td>349.0</td>\n",
              "      <td>350.0</td>\n",
              "      <td>352.0</td>\n",
              "      <td>380.0</td>\n",
              "      <td>387.0</td>\n",
              "      <td>387.0</td>\n",
              "      <td>388.0</td>\n",
              "      <td>388.0</td>\n",
              "      <td>393.0</td>\n",
              "      <td>407.0</td>\n",
              "      <td>414.0</td>\n",
              "      <td>421.0</td>\n",
              "      <td>423.0</td>\n",
              "      <td>426.0</td>\n",
              "      <td>429.0</td>\n",
              "      <td>430.0</td>\n",
              "      <td>401.0</td>\n",
              "      <td>413.0</td>\n",
              "      <td>420.0</td>\n",
              "      <td>444.0</td>\n",
              "      <td>450.0</td>\n",
              "      <td>457.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2602.0</td>\n",
              "      <td>2614.0</td>\n",
              "      <td>2630.0</td>\n",
              "      <td>2639.0</td>\n",
              "      <td>2647.0</td>\n",
              "      <td>2661.0</td>\n",
              "      <td>2665.0</td>\n",
              "      <td>2669.0</td>\n",
              "      <td>2676.0</td>\n",
              "      <td>2696.0</td>\n",
              "      <td>2720.0</td>\n",
              "      <td>2727.0</td>\n",
              "      <td>2738.0</td>\n",
              "      <td>2738.0</td>\n",
              "      <td>2765.0</td>\n",
              "      <td>2775.0</td>\n",
              "      <td>2786.0</td>\n",
              "      <td>2799.0</td>\n",
              "      <td>2812.0</td>\n",
              "      <td>2828.0</td>\n",
              "      <td>2835.0</td>\n",
              "      <td>2852.0</td>\n",
              "      <td>2867.0</td>\n",
              "      <td>2887.0</td>\n",
              "      <td>2899.0</td>\n",
              "      <td>2914.0</td>\n",
              "      <td>2932.0</td>\n",
              "      <td>2938.0</td>\n",
              "      <td>2950.0</td>\n",
              "      <td>2974.0</td>\n",
              "      <td>2990.0</td>\n",
              "      <td>3022.0</td>\n",
              "      <td>3048.0</td>\n",
              "      <td>3061.0</td>\n",
              "      <td>3069.0</td>\n",
              "      <td>3079.0</td>\n",
              "      <td>3146.0</td>\n",
              "      <td>3176.0</td>\n",
              "      <td>3203.0</td>\n",
              "      <td>75.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Barbour</th>\n",
              "      <td>74.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>105.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>147.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>167.0</td>\n",
              "      <td>173.0</td>\n",
              "      <td>176.0</td>\n",
              "      <td>178.0</td>\n",
              "      <td>178.0</td>\n",
              "      <td>184.0</td>\n",
              "      <td>191.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>198.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>209.0</td>\n",
              "      <td>215.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>227.0</td>\n",
              "      <td>235.0</td>\n",
              "      <td>238.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>263.0</td>\n",
              "      <td>266.0</td>\n",
              "      <td>272.0</td>\n",
              "      <td>272.0</td>\n",
              "      <td>277.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>288.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1161.0</td>\n",
              "      <td>1167.0</td>\n",
              "      <td>1170.0</td>\n",
              "      <td>1170.0</td>\n",
              "      <td>1171.0</td>\n",
              "      <td>1173.0</td>\n",
              "      <td>1175.0</td>\n",
              "      <td>1178.0</td>\n",
              "      <td>1189.0</td>\n",
              "      <td>1206.0</td>\n",
              "      <td>1214.0</td>\n",
              "      <td>1217.0</td>\n",
              "      <td>1219.0</td>\n",
              "      <td>1223.0</td>\n",
              "      <td>1224.0</td>\n",
              "      <td>1240.0</td>\n",
              "      <td>1245.0</td>\n",
              "      <td>1258.0</td>\n",
              "      <td>1264.0</td>\n",
              "      <td>1269.0</td>\n",
              "      <td>1272.0</td>\n",
              "      <td>1275.0</td>\n",
              "      <td>1292.0</td>\n",
              "      <td>1296.0</td>\n",
              "      <td>1309.0</td>\n",
              "      <td>1318.0</td>\n",
              "      <td>1330.0</td>\n",
              "      <td>1336.0</td>\n",
              "      <td>1336.0</td>\n",
              "      <td>1363.0</td>\n",
              "      <td>1383.0</td>\n",
              "      <td>1390.0</td>\n",
              "      <td>1396.0</td>\n",
              "      <td>1398.0</td>\n",
              "      <td>1406.0</td>\n",
              "      <td>1417.0</td>\n",
              "      <td>1462.0</td>\n",
              "      <td>1492.0</td>\n",
              "      <td>1514.0</td>\n",
              "      <td>765.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bibb</th>\n",
              "      <td>46.0</td>\n",
              "      <td>391.0</td>\n",
              "      <td>394.0</td>\n",
              "      <td>396.0</td>\n",
              "      <td>397.0</td>\n",
              "      <td>411.0</td>\n",
              "      <td>408.0</td>\n",
              "      <td>416.0</td>\n",
              "      <td>423.0</td>\n",
              "      <td>432.0</td>\n",
              "      <td>433.0</td>\n",
              "      <td>435.0</td>\n",
              "      <td>436.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>454.0</td>\n",
              "      <td>453.0</td>\n",
              "      <td>467.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>481.0</td>\n",
              "      <td>494.0</td>\n",
              "      <td>502.0</td>\n",
              "      <td>504.0</td>\n",
              "      <td>503.0</td>\n",
              "      <td>509.0</td>\n",
              "      <td>511.0</td>\n",
              "      <td>516.0</td>\n",
              "      <td>525.0</td>\n",
              "      <td>530.0</td>\n",
              "      <td>533.0</td>\n",
              "      <td>532.0</td>\n",
              "      <td>542.0</td>\n",
              "      <td>560.0</td>\n",
              "      <td>121.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>601.0</td>\n",
              "      <td>609.0</td>\n",
              "      <td>627.0</td>\n",
              "      <td>644.0</td>\n",
              "      <td>...</td>\n",
              "      <td>7441.0</td>\n",
              "      <td>7484.0</td>\n",
              "      <td>7505.0</td>\n",
              "      <td>7553.0</td>\n",
              "      <td>7583.0</td>\n",
              "      <td>7604.0</td>\n",
              "      <td>7644.0</td>\n",
              "      <td>7693.0</td>\n",
              "      <td>7753.0</td>\n",
              "      <td>7818.0</td>\n",
              "      <td>7877.0</td>\n",
              "      <td>7932.0</td>\n",
              "      <td>8006.0</td>\n",
              "      <td>8008.0</td>\n",
              "      <td>8135.0</td>\n",
              "      <td>8195.0</td>\n",
              "      <td>8274.0</td>\n",
              "      <td>8374.0</td>\n",
              "      <td>8456.0</td>\n",
              "      <td>8513.0</td>\n",
              "      <td>8566.0</td>\n",
              "      <td>8617.0</td>\n",
              "      <td>8695.0</td>\n",
              "      <td>8787.0</td>\n",
              "      <td>8858.0</td>\n",
              "      <td>8940.0</td>\n",
              "      <td>9034.0</td>\n",
              "      <td>9081.0</td>\n",
              "      <td>9137.0</td>\n",
              "      <td>9246.0</td>\n",
              "      <td>9312.0</td>\n",
              "      <td>9431.0</td>\n",
              "      <td>9549.0</td>\n",
              "      <td>9630.0</td>\n",
              "      <td>9685.0</td>\n",
              "      <td>9730.0</td>\n",
              "      <td>9829.0</td>\n",
              "      <td>9971.0</td>\n",
              "      <td>10126.0</td>\n",
              "      <td>261.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Blount</th>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>139.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>149.0</td>\n",
              "      <td>153.0</td>\n",
              "      <td>159.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2763.0</td>\n",
              "      <td>2822.0</td>\n",
              "      <td>2855.0</td>\n",
              "      <td>2879.0</td>\n",
              "      <td>2888.0</td>\n",
              "      <td>2922.0</td>\n",
              "      <td>2946.0</td>\n",
              "      <td>2997.0</td>\n",
              "      <td>3061.0</td>\n",
              "      <td>3100.0</td>\n",
              "      <td>3158.0</td>\n",
              "      <td>3231.0</td>\n",
              "      <td>3281.0</td>\n",
              "      <td>3299.0</td>\n",
              "      <td>3324.0</td>\n",
              "      <td>3426.0</td>\n",
              "      <td>3496.0</td>\n",
              "      <td>3600.0</td>\n",
              "      <td>3663.0</td>\n",
              "      <td>3744.0</td>\n",
              "      <td>3776.0</td>\n",
              "      <td>3803.0</td>\n",
              "      <td>3881.0</td>\n",
              "      <td>3950.0</td>\n",
              "      <td>4036.0</td>\n",
              "      <td>4118.0</td>\n",
              "      <td>4191.0</td>\n",
              "      <td>4218.0</td>\n",
              "      <td>4234.0</td>\n",
              "      <td>4313.0</td>\n",
              "      <td>4367.0</td>\n",
              "      <td>4405.0</td>\n",
              "      <td>4441.0</td>\n",
              "      <td>4446.0</td>\n",
              "      <td>4465.0</td>\n",
              "      <td>4483.0</td>\n",
              "      <td>4535.0</td>\n",
              "      <td>4584.0</td>\n",
              "      <td>4641.0</td>\n",
              "      <td>9976.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Prowers</th>\n",
              "      <td>9.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>...</td>\n",
              "      <td>514.0</td>\n",
              "      <td>534.0</td>\n",
              "      <td>546.0</td>\n",
              "      <td>561.0</td>\n",
              "      <td>580.0</td>\n",
              "      <td>593.0</td>\n",
              "      <td>605.0</td>\n",
              "      <td>627.0</td>\n",
              "      <td>657.0</td>\n",
              "      <td>672.0</td>\n",
              "      <td>695.0</td>\n",
              "      <td>715.0</td>\n",
              "      <td>730.0</td>\n",
              "      <td>732.0</td>\n",
              "      <td>742.0</td>\n",
              "      <td>771.0</td>\n",
              "      <td>813.0</td>\n",
              "      <td>831.0</td>\n",
              "      <td>851.0</td>\n",
              "      <td>864.0</td>\n",
              "      <td>865.0</td>\n",
              "      <td>865.0</td>\n",
              "      <td>890.0</td>\n",
              "      <td>893.0</td>\n",
              "      <td>904.0</td>\n",
              "      <td>912.0</td>\n",
              "      <td>927.0</td>\n",
              "      <td>930.0</td>\n",
              "      <td>933.0</td>\n",
              "      <td>945.0</td>\n",
              "      <td>952.0</td>\n",
              "      <td>958.0</td>\n",
              "      <td>965.0</td>\n",
              "      <td>969.0</td>\n",
              "      <td>976.0</td>\n",
              "      <td>983.0</td>\n",
              "      <td>992.0</td>\n",
              "      <td>994.0</td>\n",
              "      <td>1004.0</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pueblo</th>\n",
              "      <td>188.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>202.0</td>\n",
              "      <td>204.0</td>\n",
              "      <td>217.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>220.0</td>\n",
              "      <td>230.0</td>\n",
              "      <td>233.0</td>\n",
              "      <td>260.0</td>\n",
              "      <td>263.0</td>\n",
              "      <td>263.0</td>\n",
              "      <td>264.0</td>\n",
              "      <td>278.0</td>\n",
              "      <td>278.0</td>\n",
              "      <td>289.0</td>\n",
              "      <td>295.0</td>\n",
              "      <td>297.0</td>\n",
              "      <td>297.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>302.0</td>\n",
              "      <td>306.0</td>\n",
              "      <td>313.0</td>\n",
              "      <td>320.0</td>\n",
              "      <td>320.0</td>\n",
              "      <td>323.0</td>\n",
              "      <td>324.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>332.0</td>\n",
              "      <td>346.0</td>\n",
              "      <td>352.0</td>\n",
              "      <td>352.0</td>\n",
              "      <td>351.0</td>\n",
              "      <td>351.0</td>\n",
              "      <td>351.0</td>\n",
              "      <td>355.0</td>\n",
              "      <td>357.0</td>\n",
              "      <td>358.0</td>\n",
              "      <td>358.0</td>\n",
              "      <td>368.0</td>\n",
              "      <td>...</td>\n",
              "      <td>7028.0</td>\n",
              "      <td>7195.0</td>\n",
              "      <td>7429.0</td>\n",
              "      <td>7602.0</td>\n",
              "      <td>7860.0</td>\n",
              "      <td>8077.0</td>\n",
              "      <td>8269.0</td>\n",
              "      <td>8594.0</td>\n",
              "      <td>8856.0</td>\n",
              "      <td>9048.0</td>\n",
              "      <td>9335.0</td>\n",
              "      <td>9540.0</td>\n",
              "      <td>9749.0</td>\n",
              "      <td>9884.0</td>\n",
              "      <td>10126.0</td>\n",
              "      <td>10360.0</td>\n",
              "      <td>10650.0</td>\n",
              "      <td>10946.0</td>\n",
              "      <td>11189.0</td>\n",
              "      <td>11353.0</td>\n",
              "      <td>11415.0</td>\n",
              "      <td>11415.0</td>\n",
              "      <td>11705.0</td>\n",
              "      <td>11869.0</td>\n",
              "      <td>11990.0</td>\n",
              "      <td>12150.0</td>\n",
              "      <td>12236.0</td>\n",
              "      <td>12320.0</td>\n",
              "      <td>12407.0</td>\n",
              "      <td>12498.0</td>\n",
              "      <td>12619.0</td>\n",
              "      <td>12744.0</td>\n",
              "      <td>12827.0</td>\n",
              "      <td>12854.0</td>\n",
              "      <td>12884.0</td>\n",
              "      <td>12955.0</td>\n",
              "      <td>12991.0</td>\n",
              "      <td>13103.0</td>\n",
              "      <td>13218.0</td>\n",
              "      <td>304.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Rio Blanco</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>104.0</td>\n",
              "      <td>109.0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>148.0</td>\n",
              "      <td>149.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>181.0</td>\n",
              "      <td>182.0</td>\n",
              "      <td>184.0</td>\n",
              "      <td>204.0</td>\n",
              "      <td>207.0</td>\n",
              "      <td>209.0</td>\n",
              "      <td>209.0</td>\n",
              "      <td>221.0</td>\n",
              "      <td>221.0</td>\n",
              "      <td>229.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>245.0</td>\n",
              "      <td>247.0</td>\n",
              "      <td>249.0</td>\n",
              "      <td>252.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>257.0</td>\n",
              "      <td>257.0</td>\n",
              "      <td>260.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>264.0</td>\n",
              "      <td>266.0</td>\n",
              "      <td>267.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Routt</th>\n",
              "      <td>59.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>...</td>\n",
              "      <td>526.0</td>\n",
              "      <td>560.0</td>\n",
              "      <td>595.0</td>\n",
              "      <td>615.0</td>\n",
              "      <td>640.0</td>\n",
              "      <td>644.0</td>\n",
              "      <td>657.0</td>\n",
              "      <td>662.0</td>\n",
              "      <td>685.0</td>\n",
              "      <td>708.0</td>\n",
              "      <td>718.0</td>\n",
              "      <td>725.0</td>\n",
              "      <td>738.0</td>\n",
              "      <td>765.0</td>\n",
              "      <td>786.0</td>\n",
              "      <td>798.0</td>\n",
              "      <td>818.0</td>\n",
              "      <td>823.0</td>\n",
              "      <td>850.0</td>\n",
              "      <td>869.0</td>\n",
              "      <td>879.0</td>\n",
              "      <td>879.0</td>\n",
              "      <td>905.0</td>\n",
              "      <td>928.0</td>\n",
              "      <td>941.0</td>\n",
              "      <td>945.0</td>\n",
              "      <td>946.0</td>\n",
              "      <td>951.0</td>\n",
              "      <td>957.0</td>\n",
              "      <td>964.0</td>\n",
              "      <td>978.0</td>\n",
              "      <td>988.0</td>\n",
              "      <td>998.0</td>\n",
              "      <td>1004.0</td>\n",
              "      <td>1010.0</td>\n",
              "      <td>1013.0</td>\n",
              "      <td>1023.0</td>\n",
              "      <td>1031.0</td>\n",
              "      <td>1042.0</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Saguache</th>\n",
              "      <td>8.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>...</td>\n",
              "      <td>199.0</td>\n",
              "      <td>201.0</td>\n",
              "      <td>203.0</td>\n",
              "      <td>209.0</td>\n",
              "      <td>212.0</td>\n",
              "      <td>212.0</td>\n",
              "      <td>216.0</td>\n",
              "      <td>217.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>224.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>229.0</td>\n",
              "      <td>231.0</td>\n",
              "      <td>231.0</td>\n",
              "      <td>231.0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>235.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>239.0</td>\n",
              "      <td>239.0</td>\n",
              "      <td>240.0</td>\n",
              "      <td>240.0</td>\n",
              "      <td>241.0</td>\n",
              "      <td>245.0</td>\n",
              "      <td>246.0</td>\n",
              "      <td>246.0</td>\n",
              "      <td>246.0</td>\n",
              "      <td>247.0</td>\n",
              "      <td>247.0</td>\n",
              "      <td>250.0</td>\n",
              "      <td>251.0</td>\n",
              "      <td>251.0</td>\n",
              "      <td>251.0</td>\n",
              "      <td>252.0</td>\n",
              "      <td>253.0</td>\n",
              "      <td>252.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>277 rows × 230 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              0      1      2      3    ...      226      227      228     229\n",
              "Autauga     104.0  103.0  110.0  110.0  ...   4105.0   4164.0   4190.0    48.0\n",
              "Baldwin     243.0  282.0  284.0  287.0  ...   3146.0   3176.0   3203.0    75.0\n",
              "Barbour      74.0   79.0   79.0   81.0  ...   1462.0   1492.0   1514.0   765.0\n",
              "Bibb         46.0  391.0  394.0  396.0  ...   9829.0   9971.0  10126.0   261.0\n",
              "Blount       45.0   45.0   45.0   46.0  ...   4535.0   4584.0   4641.0  9976.0\n",
              "...           ...    ...    ...    ...  ...      ...      ...      ...     ...\n",
              "Prowers       9.0   10.0   10.0   10.0  ...    992.0    994.0   1004.0    20.0\n",
              "Pueblo      188.0  195.0  202.0  204.0  ...  12991.0  13103.0  13218.0   304.0\n",
              "Rio Blanco    1.0    1.0    1.0    1.0  ...    264.0    266.0    267.0     3.0\n",
              "Routt        59.0   59.0   59.0   59.0  ...   1023.0   1031.0   1042.0    18.0\n",
              "Saguache      8.0   16.0   16.0   16.0  ...    253.0    252.0    255.0     4.0\n",
              "\n",
              "[277 rows x 230 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wxVy9L7Bcqh",
        "outputId": "ff15f50a-350b-4c4d-b226-86b431cf6a4b"
      },
      "source": [
        "#!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Mobility_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oZ9H1kASt0O"
      },
      "source": [
        "# Perform the graph convolution between node features, adjacency matrix and count/predictor variable\n",
        "# Current path is \"/content/gdrive/My Drive/Mobility_data\"\n",
        "#path = \"/content/gdrive/My Drive/Mobility_data\"\n",
        "\n",
        "#!cd /content/gdrive/My Drive/Mobility_data\n",
        "file_count = 1\n",
        "nodes = 277\n",
        "cov_feats = 1\n",
        "\n",
        "for f in date_list: # take days in sequence\n",
        "    file = glob.glob(f)\n",
        "    #print (\"FIRST DAY MOBILITY:\", file)\n",
        "    if  (len(file)) == 1:\n",
        "      mob_data = pd.read_csv(file[0])\n",
        "    else:\n",
        "      continue\n",
        "  \n",
        "    # create adj matrix\n",
        "    adj_mat = pd.DataFrame( columns = column_name,\n",
        "                    index=column_name) \n",
        "    \n",
        "     # Create  node features matrix X # Nos of days * nos of node feats(people mobility at node and infection cases)\n",
        "    df_X = pd.DataFrame( columns = [\"mean_distance_traveled_from_home\"], index=column_name)\n",
        "   \n",
        "\n",
        "    ## Dynamic adjacency matrix for each day\n",
        "    for index,row in mob_data.iterrows():\n",
        "        county_origin = row[\"origin_county_FIPS\"]\n",
        "        county_dest = row[\"destination_county_FIPS\"]\n",
        "        agg_visits = row[\"agg_visits\"]\n",
        "        mean_distance_traveled_from_home = row[\"mean_distance_traveled_from_home\"]\n",
        "        \n",
        "\n",
        "        if county_origin in column_name:\n",
        "          if county_dest in column_name:\n",
        "            # Create covarite matrix with the mean distance for each day\n",
        "            df_X.loc[county_origin,\"mean_distance_traveled_from_home\"] = mean_distance_traveled_from_home\n",
        "\n",
        "            # Create the edges of adj matrix based on nos of visits \n",
        "            if  agg_visits > 200:            \n",
        "              adj_mat.loc[county_origin,county_dest] = agg_visits\n",
        "            else:\n",
        "              adj_mat.loc[county_origin,county_dest] = 0.000001\n",
        "\n",
        "    adj_mat = adj_mat.replace(np.nan,0.000001) ## no connections\n",
        "    print (\"Shape adj_mat:\", np.shape(adj_mat))\n",
        "    #print (\"adj_mat:\", adj_mat)\n",
        "\n",
        "\n",
        "\n",
        "    # pearson correlation of adjacency matrix\n",
        "    R1 = np.corrcoef(adj_mat)\n",
        "    adj_mat_coerr = pd.DataFrame(R1,columns = column_name,\n",
        "                        index=column_name)\n",
        "    #adj_mat_coerr.to_csv(\"/content/gdrive/My Drive/df_coerr.csv\",index=False)\n",
        "\n",
        "    print (\"Shape adj_mat_coerr:\", np.shape(adj_mat_coerr))\n",
        "    #print (\"adj_mat_coerr:\", adj_mat_coerr)\n",
        "  \n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "    # #Get cases data\n",
        "    # cases_data_df = pd.read_csv(\"/content/gdrive/My Drive/DeepAR-pytorch-master/data/elect/COUNTY_CASES_DATA.csv\")\n",
        "    # cases_data_df = cases_data_df.iloc[:,1:]\n",
        "    # cases_data_df_T = cases_data_df.T # Add all counties cases for single day to df_X\n",
        "    # # there is 1 nan\n",
        "    #df_X = df_X.replace(np.nan,df_X.mean())\n",
        "    \n",
        "\n",
        "    #Append covariates cases and mobility\n",
        "    #print (\"df_X:\", df_X)\n",
        "    # df_X[\"cases\"] = cases_data_df_T.iloc[:,file_count-1].to_numpy() # append one day column\n",
        "    # print (\"Shape df_x:\", np.shape(df_X)) \n",
        "    # #print (\"df_x:\", df_X)\n",
        "\n",
        "    # convert pd to tensors for adj matrix and input covariates(mobility)\n",
        "    adj_mat_coerr = torch.Tensor(adj_mat_coerr.values)\n",
        "    adj_mat = torch.Tensor(adj_mat.values)\n",
        "    inp = torch.Tensor(df_X.values.astype(float))\n",
        "    inp = torch.reshape(inp,(nodes,cov_feats))\n",
        "    print (\"inp shape:\", np.shape(inp))\n",
        "    #print (\"INP:\", inp)\n",
        "\n",
        "      \n",
        "\n",
        "   # Perform GCN ((W_0.(D_0^-1.A) + W_1.(D_1^-1.A))X\n",
        "    \n",
        "    weight = Parameter(torch.Tensor(nodes,nodes))\n",
        "\n",
        "    #stdv = 1. / math.sqrt(weight.size(1))\n",
        "    #weight.data.uniform_(-stdv, stdv)\n",
        "    nn.init.xavier_normal_(weight.data, gain=0.02) \n",
        "\n",
        "    #Add normalization to degree matrix\n",
        "    D_inverse= torch.diag(1 / torch.sum(adj_mat_coerr, 0))\n",
        "    norm_A = torch.matmul(D_inverse, adj_mat_coerr)\n",
        "\n",
        "\n",
        "    # Perform Graph Conv   \n",
        "    support = torch.spmm(weight,norm_A)\n",
        "    print (\"support:\", np.shape(support))\n",
        "    \n",
        "\n",
        "    output = torch.mm(support,inp)\n",
        "    #print (\"output:\", output)\n",
        "    print (\"output shape:\", np.shape(output))\n",
        "\n",
        "    # Save each graph convoluted covariate matrix for each day ## Nos of days * X(node) features     \n",
        "    covariate_matrix = 'covariate_matrix_day_'+ str(file_count)+\".csv\"\n",
        "    file_count = file_count + 1\n",
        "\n",
        "    new_path = \"/content/gdrive/My Drive/covariate_mat_300_MOBILITY_ORIG_200V_V1/\"\n",
        "    save_path = new_path + covariate_matrix\n",
        "    print (\"save path:\", save_path)\n",
        "    output_final = pd.DataFrame(output.detach().numpy())\n",
        "    output_final.to_csv(save_path, index=False)\n",
        "\n",
        "    "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TEfexrbiKRQ",
        "outputId": "70b2034a-220a-456c-bc8a-df7a4a274f21"
      },
      "source": [
        "\n",
        "!pwd\n",
        "\n",
        "%cd /content/gdrive/My Drive/DeepAR-pytorch-master/\n",
        "\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/DeepAR-pytorch-master\n",
            "/content/gdrive/My Drive/DeepAR-pytorch-master\n",
            "/content/gdrive/My Drive/DeepAR-pytorch-master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzfUJsCEPVnI"
      },
      "source": [
        "# Ouput/predictor variable (Z)\n",
        "# cases = pd.read_csv(\"data/elect/county_cases_data.csv\")\n",
        "# #cases = cases.drop([\"Days\"], axis = 1)\n",
        "# cases"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWyY2rXfiRrM"
      },
      "source": [
        "# Preprocess the data\n",
        "!python3 preprocess_mobility_cases_dynamic_feats.py"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cq6kmY3DY5pV"
      },
      "source": [
        "path = \"/content/gdrive/My Drive/covariate_mat_300_xavier_CASES_MOBILITY_feats_threshold_newcovariate_mat_300_xavier_NODE_MOBILITY_feats_threshold/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kIadAqLiU_6",
        "outputId": "d16abd64-9707-4cc3-ba27-d4a0e1f024ee"
      },
      "source": [
        "!python3 train.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PARAMETERS: {'learning_rate': 0.001, 'batch_size': 4, 'lstm_layers': 5, 'num_epochs': 50, 'train_window': 12, 'test_window': 12, 'predict_start': 8, 'test_predict_start': 8, 'predict_steps': 4, 'num_class': 277, 'cov_dim': 554, 'lstm_hidden_dim': 40, 'embedding_dim': 20, 'sample_times': 12, 'lstm_dropout': 0.3, 'predict_batch': 10}\n",
            "[16:54:56] DeepAR.Train: Loading the datasets...\n",
            "feat shape: (8310, 12, 556)\n",
            "label shape: (8310, 12)\n",
            "[16:54:57] DeepAR.Data: train_len: 8310\n",
            "[16:54:57] DeepAR.Data: building datasets from data/elect...\n",
            "[16:54:57] DeepAR.Data: test_len: 277\n",
            "[16:54:57] DeepAR.Data: building datasets from data/elect...\n",
            "[16:54:57] DeepAR.Data: weights: tensor([2.6571e-05, 2.7567e-05, 2.7899e-05,  ..., 9.4160e-05, 1.0280e-04,\n",
            "        1.1376e-04], dtype=torch.float64)\n",
            "[16:54:57] DeepAR.Data: num samples: 8310\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "[16:54:57] DeepAR.Train: Loading complete.\n",
            "[16:54:57] DeepAR.Train: Model: \n",
            "Net(\n",
            "  (embedding): Embedding(277, 20)\n",
            "  (lstm): LSTM(575, 40, num_layers=5, dropout=0.3)\n",
            "  (relu): ReLU()\n",
            "  (distribution_mu): Linear(in_features=200, out_features=1, bias=True)\n",
            "  (distribution_presigma): Linear(in_features=200, out_features=1, bias=True)\n",
            "  (distribution_sigma): Softplus(beta=1, threshold=20)\n",
            ")\n",
            "[16:54:57] DeepAR.Train: Starting training for 50 epoch(s)\n",
            "[16:54:57] DeepAR.Train: begin training and evaluation\n",
            "[16:54:57] DeepAR.Train: Epoch 1/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            " 11% 3/28 [00:00<00:00, 29.92it/s]\u001b[A\n",
            " 43% 12/28 [00:03<00:02,  6.62it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.78it/s]\n",
            "[16:55:01] DeepAR.Eval: - Full test metrics: ND: 0.734; RMSE: 3.137; test_loss: 4.514\n",
            "[16:55:01] DeepAR.Train: train_loss: 1.6476964950561523\n",
            "[16:55:01] DeepAR.Train: train_loss: 1.6476964950561523\n",
            " 48% 999/2078 [00:48<00:42, 25.50it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            " 11% 3/28 [00:00<00:00, 25.71it/s]\u001b[A\n",
            " 14% 4/28 [00:03<00:26,  1.09s/it]\u001b[A\n",
            " 43% 12/28 [00:03<00:12,  1.31it/s]\u001b[A\n",
            "100% 28/28 [00:03<00:00,  7.02it/s]\n",
            "[16:55:50] DeepAR.Eval: - Full test metrics: ND: 0.031; RMSE: 0.084; test_loss: 8.794\n",
            "[16:55:50] DeepAR.Train: train_loss: -1.5963161786397297\n",
            " 96% 1999/2078 [01:38<00:03, 23.27it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:03<01:46,  3.94s/it]\u001b[A\n",
            " 29% 8/28 [00:04<00:55,  2.76s/it]\u001b[A\n",
            " 57% 16/28 [00:04<00:23,  1.94s/it]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.44it/s]\n",
            "[16:56:40] DeepAR.Eval: - Full test metrics: ND: 0.033; RMSE: 0.106; test_loss: 14.179\n",
            "[16:56:40] DeepAR.Train: train_loss: -1.3555059432983398\n",
            "100% 2078/2078 [01:46<00:00, 19.50it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.59it/s]\n",
            "[16:56:48] DeepAR.Eval: - Full test metrics: ND: 0.041; RMSE: 0.195; test_loss: 4.760\n",
            "[16:56:48] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_0.pth.tar\n",
            "[16:56:48] DeepAR.Utils: Best checkpoint copied to best.pth.tar\n",
            "[16:56:48] DeepAR.Train: - Found new best ND\n",
            "[16:56:48] DeepAR.Train: Current Best ND is: 0.04130\n",
            "[16:56:49] DeepAR.Train: Epoch 2/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  7% 2/28 [00:00<00:01, 18.00it/s]\u001b[A\n",
            " 32% 9/28 [00:00<00:00, 23.07it/s]\u001b[A\n",
            " 61% 17/28 [00:00<00:00, 29.16it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.47it/s]\n",
            "[16:56:53] DeepAR.Eval: - Full test metrics: ND: 0.040; RMSE: 0.185; test_loss: 4.609\n",
            "[16:56:53] DeepAR.Train: train_loss: -1.169548749923706\n",
            "[16:56:53] DeepAR.Train: train_loss: -1.169548749923706\n",
            " 48% 1000/2078 [00:50<00:54, 19.67it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:02,  9.97it/s]\u001b[A\n",
            " 32% 9/28 [00:00<00:01, 13.47it/s]\u001b[A\n",
            " 61% 17/28 [00:00<00:00, 17.79it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.40it/s]\n",
            "[16:57:44] DeepAR.Eval: - Full test metrics: ND: 0.028; RMSE: 0.081; test_loss: 5.974\n",
            "[16:57:44] DeepAR.Train: train_loss: -1.5194536844889324\n",
            " 96% 1998/2078 [01:41<00:03, 21.20it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            " 11% 3/28 [00:00<00:00, 27.67it/s]\u001b[A\n",
            " 43% 12/28 [00:00<00:00, 34.48it/s]\u001b[A\n",
            " 71% 20/28 [00:00<00:00, 41.49it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.96it/s]\n",
            "[16:58:34] DeepAR.Eval: - Full test metrics: ND: 0.036; RMSE: 0.079; test_loss: 3.311\n",
            "[16:58:34] DeepAR.Train: train_loss: -1.1736831665039062\n",
            "100% 2078/2078 [01:48<00:00, 19.11it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.88it/s]\n",
            "[16:58:42] DeepAR.Eval: - Full test metrics: ND: 0.033; RMSE: 0.126; test_loss: 6.739\n",
            "[16:58:42] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_1.pth.tar\n",
            "[16:58:42] DeepAR.Utils: Best checkpoint copied to best.pth.tar\n",
            "[16:58:42] DeepAR.Train: - Found new best ND\n",
            "[16:58:42] DeepAR.Train: Current Best ND is: 0.03276\n",
            "[16:58:42] DeepAR.Train: Epoch 3/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  7% 2/28 [00:00<00:01, 17.76it/s]\u001b[A\n",
            " 36% 10/28 [00:03<00:03,  5.53it/s]\u001b[A\n",
            " 64% 18/28 [00:03<00:01,  7.67it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.78it/s]\n",
            "[16:58:46] DeepAR.Eval: - Full test metrics: ND: 0.031; RMSE: 0.118; test_loss: 6.821\n",
            "[16:58:46] DeepAR.Train: train_loss: -2.076490561167399\n",
            "[16:58:46] DeepAR.Train: train_loss: -2.076490561167399\n",
            " 48% 998/2078 [00:51<00:45, 23.54it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  7% 2/28 [00:00<00:01, 17.07it/s]\u001b[A\n",
            " 39% 11/28 [00:00<00:00, 22.35it/s]\u001b[A\n",
            " 71% 20/28 [00:00<00:00, 28.73it/s]\u001b[A\n",
            "100% 28/28 [00:03<00:00,  7.28it/s]\n",
            "[16:59:37] DeepAR.Eval: - Full test metrics: ND: 0.024; RMSE: 0.060; test_loss: 10.925\n",
            "[16:59:37] DeepAR.Train: train_loss: -2.6564582188924155\n",
            " 96% 2000/2078 [01:41<00:03, 19.91it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:02,  9.11it/s]\u001b[A\n",
            " 32% 9/28 [00:00<00:01, 12.38it/s]\u001b[A\n",
            " 57% 16/28 [00:00<00:00, 16.43it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.29it/s]\n",
            "[17:00:28] DeepAR.Eval: - Full test metrics: ND: 0.027; RMSE: 0.081; test_loss: 7.375\n",
            "[17:00:28] DeepAR.Train: train_loss: -2.528169790903727\n",
            "100% 2078/2078 [01:49<00:00, 18.94it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.47it/s]\n",
            "[17:00:36] DeepAR.Eval: - Full test metrics: ND: 0.037; RMSE: 0.158; test_loss: 7.837\n",
            "[17:00:36] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_2.pth.tar\n",
            "[17:00:36] DeepAR.Train: Current Best ND is: 0.03276\n",
            "[17:00:37] DeepAR.Train: Epoch 4/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:02,  9.71it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:01, 13.04it/s]\u001b[A\n",
            " 61% 17/28 [00:04<00:02,  5.42it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.51it/s]\n",
            "[17:00:41] DeepAR.Eval: - Full test metrics: ND: 0.035; RMSE: 0.146; test_loss: 8.230\n",
            "[17:00:41] DeepAR.Train: train_loss: -2.345421473185221\n",
            "[17:00:41] DeepAR.Train: train_loss: -2.345421473185221\n",
            " 48% 998/2078 [00:52<00:54, 19.89it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:02,  9.36it/s]\u001b[A\n",
            " 32% 9/28 [00:00<00:01, 12.67it/s]\u001b[A\n",
            " 57% 16/28 [00:00<00:00, 16.77it/s]\u001b[A\n",
            " 71% 20/28 [00:04<00:02,  2.96it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.38it/s]\n",
            "[17:01:34] DeepAR.Eval: - Full test metrics: ND: 0.026; RMSE: 0.061; test_loss: 6.196\n",
            "[17:01:34] DeepAR.Train: train_loss: -2.619649569193522\n",
            " 96% 2000/2078 [01:46<00:03, 20.04it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  8.52it/s]\u001b[A\n",
            " 11% 3/28 [00:04<00:17,  1.46it/s]\u001b[A\n",
            " 39% 11/28 [00:04<00:08,  2.07it/s]\u001b[A\n",
            " 68% 19/28 [00:04<00:03,  2.92it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.21it/s]\n",
            "[17:02:28] DeepAR.Eval: - Full test metrics: ND: 0.026; RMSE: 0.060; test_loss: 7.090\n",
            "[17:02:28] DeepAR.Train: train_loss: -2.4601964950561523\n",
            "100% 2078/2078 [01:54<00:00, 18.11it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.91it/s]\n",
            "[17:02:36] DeepAR.Eval: - Full test metrics: ND: 0.026; RMSE: 0.056; test_loss: 4.922\n",
            "[17:02:36] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_3.pth.tar\n",
            "[17:02:36] DeepAR.Utils: Best checkpoint copied to best.pth.tar\n",
            "[17:02:36] DeepAR.Train: - Found new best ND\n",
            "[17:02:36] DeepAR.Train: Current Best ND is: 0.02558\n",
            "[17:02:36] DeepAR.Train: Epoch 5/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:02,  9.51it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:01, 12.78it/s]\u001b[A\n",
            " 54% 15/28 [00:00<00:00, 16.87it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.37it/s]\n",
            "[17:02:41] DeepAR.Eval: - Full test metrics: ND: 0.026; RMSE: 0.058; test_loss: 5.074\n",
            "[17:02:41] DeepAR.Train: train_loss: -2.580756187438965\n",
            "[17:02:41] DeepAR.Train: train_loss: -2.580756187438965\n",
            " 48% 999/2078 [00:55<00:56, 19.00it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:02,  9.18it/s]\u001b[A\n",
            " 25% 7/28 [00:03<00:05,  3.73it/s]\u001b[A\n",
            " 50% 14/28 [00:04<00:02,  5.19it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.54it/s]\n",
            "[17:03:36] DeepAR.Eval: - Full test metrics: ND: 0.029; RMSE: 0.067; test_loss: 3.186\n",
            "[17:03:36] DeepAR.Train: train_loss: -3.291846593221029\n",
            " 96% 1999/2078 [01:49<00:03, 20.21it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  7% 2/28 [00:00<00:01, 18.12it/s]\u001b[A\n",
            " 36% 10/28 [00:00<00:00, 23.45it/s]\u001b[A\n",
            " 64% 18/28 [00:00<00:00, 29.27it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.58it/s]\n",
            "[17:04:30] DeepAR.Eval: - Full test metrics: ND: 0.027; RMSE: 0.064; test_loss: 4.140\n",
            "[17:04:30] DeepAR.Train: train_loss: -3.0469350814819336\n",
            "100% 2078/2078 [01:57<00:00, 17.66it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.39it/s]\n",
            "[17:04:38] DeepAR.Eval: - Full test metrics: ND: 0.029; RMSE: 0.067; test_loss: 4.766\n",
            "[17:04:39] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_4.pth.tar\n",
            "[17:04:39] DeepAR.Train: Current Best ND is: 0.02558\n",
            "[17:04:39] DeepAR.Train: Epoch 6/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:02,  9.68it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:01, 13.00it/s]\u001b[A\n",
            " 54% 15/28 [00:00<00:00, 17.17it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.04it/s]\n",
            "[17:04:44] DeepAR.Eval: - Full test metrics: ND: 0.028; RMSE: 0.064; test_loss: 4.721\n",
            "[17:04:44] DeepAR.Train: train_loss: -3.2992547353108725\n",
            "[17:04:44] DeepAR.Train: train_loss: -3.2992547353108725\n",
            " 48% 1000/2078 [00:55<00:55, 19.46it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  8.78it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:01, 11.86it/s]\u001b[A\n",
            " 54% 15/28 [00:00<00:00, 15.73it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.25it/s]\n",
            "[17:05:39] DeepAR.Eval: - Full test metrics: ND: 0.030; RMSE: 0.077; test_loss: 3.205\n",
            "[17:05:39] DeepAR.Train: train_loss: -2.762484550476074\n",
            " 96% 2000/2078 [01:47<00:03, 19.83it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  7% 2/28 [00:00<00:01, 16.99it/s]\u001b[A\n",
            " 36% 10/28 [00:00<00:00, 21.93it/s]\u001b[A\n",
            " 46% 13/28 [00:04<00:06,  2.34it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.34it/s]\n",
            "[17:06:31] DeepAR.Eval: - Full test metrics: ND: 0.028; RMSE: 0.068; test_loss: 3.903\n",
            "[17:06:31] DeepAR.Train: train_loss: -3.1060158411661782\n",
            "100% 2078/2078 [01:56<00:00, 17.87it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.62it/s]\n",
            "[17:06:39] DeepAR.Eval: - Full test metrics: ND: 0.033; RMSE: 0.089; test_loss: 3.915\n",
            "[17:06:40] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_5.pth.tar\n",
            "[17:06:40] DeepAR.Train: Current Best ND is: 0.02558\n",
            "[17:06:40] DeepAR.Train: Epoch 7/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:03<01:45,  3.92s/it]\u001b[A\n",
            " 32% 9/28 [00:04<00:52,  2.75s/it]\u001b[A\n",
            " 61% 17/28 [00:04<00:21,  1.93s/it]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.49it/s]\n",
            "[17:06:45] DeepAR.Eval: - Full test metrics: ND: 0.032; RMSE: 0.083; test_loss: 3.855\n",
            "[17:06:45] DeepAR.Train: train_loss: -3.046799341837565\n",
            "[17:06:45] DeepAR.Train: train_loss: -3.046799341837565\n",
            " 48% 998/2078 [00:53<00:54, 19.80it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:02,  9.21it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:01, 12.45it/s]\u001b[A\n",
            " 54% 15/28 [00:00<00:00, 16.49it/s]\u001b[A\n",
            " 68% 19/28 [00:04<00:03,  3.00it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.46it/s]\n",
            "[17:07:38] DeepAR.Eval: - Full test metrics: ND: 0.025; RMSE: 0.058; test_loss: 5.540\n",
            "[17:07:38] DeepAR.Train: train_loss: -3.0388100941975913\n",
            " 96% 1999/2078 [01:47<00:04, 19.39it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  7.88it/s]\u001b[A\n",
            " 21% 6/28 [00:04<00:07,  3.07it/s]\u001b[A\n",
            " 50% 14/28 [00:04<00:03,  4.31it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.36it/s]\n",
            "[17:08:32] DeepAR.Eval: - Full test metrics: ND: 0.045; RMSE: 0.131; test_loss: 3.194\n",
            "[17:08:32] DeepAR.Train: train_loss: -0.748366117477417\n",
            "100% 2078/2078 [01:55<00:00, 17.96it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.33it/s]\n",
            "[17:08:40] DeepAR.Eval: - Full test metrics: ND: 0.027; RMSE: 0.060; test_loss: 6.793\n",
            "[17:08:40] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_6.pth.tar\n",
            "[17:08:40] DeepAR.Train: Current Best ND is: 0.02558\n",
            "[17:08:41] DeepAR.Train: Epoch 8/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  7% 2/28 [00:00<00:01, 18.08it/s]\u001b[A\n",
            " 14% 4/28 [00:04<00:15,  1.54it/s]\u001b[A\n",
            " 46% 13/28 [00:04<00:06,  2.19it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.25it/s]\n",
            "[17:08:45] DeepAR.Eval: - Full test metrics: ND: 0.027; RMSE: 0.061; test_loss: 6.976\n",
            "[17:08:45] DeepAR.Train: train_loss: -3.1490532557169595\n",
            "[17:08:45] DeepAR.Train: train_loss: -3.1490532557169595\n",
            " 48% 999/2078 [00:53<00:56, 19.17it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:02,  9.16it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:01, 12.37it/s]\u001b[A\n",
            " 57% 16/28 [00:04<00:02,  4.89it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.49it/s]\n",
            "[17:09:39] DeepAR.Eval: - Full test metrics: ND: 0.025; RMSE: 0.056; test_loss: 4.216\n",
            "[17:09:39] DeepAR.Train: train_loss: -2.5605362256368003\n",
            " 96% 2000/2078 [01:48<00:04, 19.26it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  8.38it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:01, 11.34it/s]\u001b[A\n",
            " 54% 15/28 [00:00<00:00, 15.10it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.62it/s]\n",
            "[17:10:34] DeepAR.Eval: - Full test metrics: ND: 0.023; RMSE: 0.052; test_loss: 5.626\n",
            "[17:10:34] DeepAR.Train: train_loss: -3.5946922302246094\n",
            "100% 2078/2078 [01:57<00:00, 17.73it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.35it/s]\n",
            "[17:10:42] DeepAR.Eval: - Full test metrics: ND: 0.025; RMSE: 0.061; test_loss: 4.783\n",
            "[17:10:43] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_7.pth.tar\n",
            "[17:10:43] DeepAR.Utils: Best checkpoint copied to best.pth.tar\n",
            "[17:10:43] DeepAR.Train: - Found new best ND\n",
            "[17:10:43] DeepAR.Train: Current Best ND is: 0.02543\n",
            "[17:10:43] DeepAR.Train: Epoch 9/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:18,  1.42it/s]\u001b[A\n",
            " 11% 3/28 [00:00<00:13,  1.91it/s]\u001b[A\n",
            " 39% 11/28 [00:01<00:06,  2.70it/s]\u001b[A\n",
            " 68% 19/28 [00:01<00:02,  3.80it/s]\u001b[A\n",
            "100% 28/28 [00:05<00:00,  5.36it/s]\n",
            "[17:10:48] DeepAR.Eval: - Full test metrics: ND: 0.025; RMSE: 0.060; test_loss: 4.764\n",
            "[17:10:48] DeepAR.Train: train_loss: -2.3876752853393555\n",
            "[17:10:48] DeepAR.Train: train_loss: -2.3876752853393555\n",
            " 48% 999/2078 [00:56<00:52, 20.38it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:02,  9.68it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:01, 13.01it/s]\u001b[A\n",
            " 50% 14/28 [00:04<00:03,  4.03it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.47it/s]\n",
            "[17:11:43] DeepAR.Eval: - Full test metrics: ND: 0.026; RMSE: 0.066; test_loss: 4.728\n",
            "[17:11:43] DeepAR.Train: train_loss: -3.62554931640625\n",
            " 96% 2000/2078 [01:48<00:03, 24.80it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  7% 2/28 [00:00<00:01, 17.64it/s]\u001b[A\n",
            " 36% 10/28 [00:04<00:03,  5.32it/s]\u001b[A\n",
            " 61% 17/28 [00:04<00:01,  7.35it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.44it/s]\n",
            "[17:12:36] DeepAR.Eval: - Full test metrics: ND: 0.027; RMSE: 0.064; test_loss: 3.526\n",
            "[17:12:36] DeepAR.Train: train_loss: -2.9582573572794595\n",
            "100% 2078/2078 [01:56<00:00, 17.81it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.74it/s]\n",
            "[17:12:44] DeepAR.Eval: - Full test metrics: ND: 0.028; RMSE: 0.065; test_loss: 2.616\n",
            "[17:12:44] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_8.pth.tar\n",
            "[17:12:44] DeepAR.Train: Current Best ND is: 0.02543\n",
            "[17:12:44] DeepAR.Train: Epoch 10/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:03,  8.96it/s]\u001b[A\n",
            " 11% 3/28 [00:04<00:16,  1.48it/s]\u001b[A\n",
            " 43% 12/28 [00:04<00:07,  2.10it/s]\u001b[A\n",
            " 71% 20/28 [00:04<00:02,  2.97it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.33it/s]\n",
            "[17:12:49] DeepAR.Eval: - Full test metrics: ND: 0.027; RMSE: 0.062; test_loss: 2.658\n",
            "[17:12:49] DeepAR.Train: train_loss: -3.6505346298217773\n",
            "[17:12:49] DeepAR.Train: train_loss: -3.6505346298217773\n",
            " 48% 998/2078 [00:51<00:45, 23.81it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            " 11% 3/28 [00:00<00:00, 27.07it/s]\u001b[A\n",
            " 39% 11/28 [00:00<00:00, 33.31it/s]\u001b[A\n",
            " 57% 16/28 [00:03<00:02,  4.06it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.73it/s]\n",
            "[17:13:40] DeepAR.Eval: - Full test metrics: ND: 0.026; RMSE: 0.065; test_loss: 3.387\n",
            "[17:13:40] DeepAR.Train: train_loss: -3.2665907541910806\n",
            " 96% 2000/2078 [01:44<00:04, 19.30it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:02,  9.34it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:01, 12.60it/s]\u001b[A\n",
            " 57% 16/28 [00:00<00:00, 16.76it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.99it/s]\n",
            "[17:14:32] DeepAR.Eval: - Full test metrics: ND: 0.032; RMSE: 0.090; test_loss: 2.855\n",
            "[17:14:32] DeepAR.Train: train_loss: -2.9606618881225586\n",
            "100% 2078/2078 [01:52<00:00, 18.50it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.54it/s]\n",
            "[17:14:41] DeepAR.Eval: - Full test metrics: ND: 0.031; RMSE: 0.082; test_loss: 2.752\n",
            "[17:14:41] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_9.pth.tar\n",
            "[17:14:41] DeepAR.Train: Current Best ND is: 0.02543\n",
            "[17:14:41] DeepAR.Train: Epoch 11/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  7% 2/28 [00:00<00:01, 16.36it/s]\u001b[A\n",
            " 36% 10/28 [00:04<00:03,  5.29it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.59it/s]\n",
            "[17:14:46] DeepAR.Eval: - Full test metrics: ND: 0.033; RMSE: 0.091; test_loss: 2.755\n",
            "[17:14:46] DeepAR.Train: train_loss: -3.0661408106486\n",
            "[17:14:46] DeepAR.Train: train_loss: -3.0661408106486\n",
            " 48% 1000/2078 [00:52<00:55, 19.36it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:02,  9.09it/s]\u001b[A\n",
            " 32% 9/28 [00:00<00:01, 12.32it/s]\u001b[A\n",
            " 54% 15/28 [00:00<00:00, 16.12it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.88it/s]\n",
            "[17:15:38] DeepAR.Eval: - Full test metrics: ND: 0.025; RMSE: 0.060; test_loss: 2.373\n",
            "[17:15:38] DeepAR.Train: train_loss: -2.304750124613444\n",
            " 96% 2000/2078 [01:43<00:03, 24.11it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  7% 2/28 [00:00<00:01, 19.82it/s]\u001b[A\n",
            " 36% 10/28 [00:03<00:03,  5.71it/s]\u001b[A\n",
            " 64% 18/28 [00:03<00:01,  7.91it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.88it/s]\n",
            "[17:16:29] DeepAR.Eval: - Full test metrics: ND: 0.025; RMSE: 0.060; test_loss: 2.816\n",
            "[17:16:29] DeepAR.Train: train_loss: -2.8539018630981445\n",
            "100% 2078/2078 [01:51<00:00, 18.57it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.93it/s]\n",
            "[17:16:37] DeepAR.Eval: - Full test metrics: ND: 0.025; RMSE: 0.069; test_loss: 2.373\n",
            "[17:16:38] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_10.pth.tar\n",
            "[17:16:38] DeepAR.Utils: Best checkpoint copied to best.pth.tar\n",
            "[17:16:38] DeepAR.Train: - Found new best ND\n",
            "[17:16:38] DeepAR.Train: Current Best ND is: 0.02479\n",
            "[17:16:38] DeepAR.Train: Epoch 12/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  7% 2/28 [00:00<00:01, 17.88it/s]\u001b[A\n",
            " 11% 3/28 [00:04<00:32,  1.29s/it]\u001b[A\n",
            " 43% 12/28 [00:04<00:14,  1.11it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.10it/s]\n",
            "[17:16:42] DeepAR.Eval: - Full test metrics: ND: 0.025; RMSE: 0.066; test_loss: 2.370\n",
            "[17:16:42] DeepAR.Train: train_loss: -2.606393019358317\n",
            "[17:16:42] DeepAR.Train: train_loss: -2.606393019358317\n",
            " 48% 998/2078 [00:51<00:54, 19.99it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  7% 2/28 [00:00<00:01, 16.12it/s]\u001b[A\n",
            " 21% 6/28 [00:03<00:06,  3.19it/s]\u001b[A\n",
            " 50% 14/28 [00:03<00:03,  4.47it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.90it/s]\n",
            "[17:17:33] DeepAR.Eval: - Full test metrics: ND: 0.026; RMSE: 0.060; test_loss: 2.274\n",
            "[17:17:33] DeepAR.Train: train_loss: -2.3366095225016275\n",
            " 96% 1998/2078 [01:44<00:03, 24.16it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  7% 2/28 [00:00<00:01, 19.34it/s]\u001b[A\n",
            " 32% 9/28 [00:03<00:03,  5.07it/s]\u001b[A\n",
            " 61% 17/28 [00:03<00:01,  7.04it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.74it/s]\n",
            "[17:18:26] DeepAR.Eval: - Full test metrics: ND: 0.030; RMSE: 0.083; test_loss: 2.084\n",
            "[17:18:26] DeepAR.Train: train_loss: -3.91501522064209\n",
            "100% 2078/2078 [01:52<00:00, 18.51it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.17it/s]\n",
            "[17:18:35] DeepAR.Eval: - Full test metrics: ND: 0.026; RMSE: 0.067; test_loss: 2.020\n",
            "[17:18:35] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_11.pth.tar\n",
            "[17:18:35] DeepAR.Train: Current Best ND is: 0.02479\n",
            "[17:18:35] DeepAR.Train: Epoch 13/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  7% 2/28 [00:00<00:01, 19.18it/s]\u001b[A\n",
            " 36% 10/28 [00:00<00:00, 24.79it/s]\u001b[A\n",
            " 54% 15/28 [00:04<00:03,  3.69it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.32it/s]\n",
            "[17:18:40] DeepAR.Eval: - Full test metrics: ND: 0.028; RMSE: 0.074; test_loss: 2.018\n",
            "[17:18:40] DeepAR.Train: train_loss: -3.1457153956095376\n",
            "[17:18:40] DeepAR.Train: train_loss: -3.1457153956095376\n",
            " 48% 999/2078 [00:51<00:45, 23.50it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  7% 2/28 [00:00<00:01, 19.69it/s]\u001b[A\n",
            " 25% 7/28 [00:03<00:05,  4.04it/s]\u001b[A\n",
            " 54% 15/28 [00:03<00:02,  5.64it/s]\u001b[A\n",
            "100% 28/28 [00:03<00:00,  7.15it/s]\n",
            "[17:19:31] DeepAR.Eval: - Full test metrics: ND: 0.028; RMSE: 0.073; test_loss: 2.324\n",
            "[17:19:31] DeepAR.Train: train_loss: -2.8445202509562173\n",
            " 96% 1999/2078 [01:44<00:03, 19.76it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:02,  9.22it/s]\u001b[A\n",
            " 25% 7/28 [00:04<00:05,  3.64it/s]\u001b[A\n",
            " 57% 16/28 [00:04<00:02,  5.10it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.37it/s]\n",
            "[17:20:24] DeepAR.Eval: - Full test metrics: ND: 0.027; RMSE: 0.074; test_loss: 2.677\n",
            "[17:20:24] DeepAR.Train: train_loss: -2.9132680892944336\n",
            "100% 2078/2078 [01:52<00:00, 18.45it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.25it/s]\n",
            "[17:20:32] DeepAR.Eval: - Full test metrics: ND: 0.025; RMSE: 0.061; test_loss: 2.759\n",
            "[17:20:32] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_12.pth.tar\n",
            "[17:20:32] DeepAR.Train: Current Best ND is: 0.02479\n",
            "[17:20:33] DeepAR.Train: Epoch 14/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:03,  8.91it/s]\u001b[A\n",
            "  7% 2/28 [00:04<00:34,  1.34s/it]\u001b[A\n",
            " 36% 10/28 [00:04<00:17,  1.06it/s]\u001b[A\n",
            " 64% 18/28 [00:04<00:06,  1.50it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  5.98it/s]\n",
            "[17:20:37] DeepAR.Eval: - Full test metrics: ND: 0.023; RMSE: 0.053; test_loss: 2.759\n",
            "[17:20:37] DeepAR.Train: train_loss: -3.6636667251586914\n",
            "[17:20:37] DeepAR.Train: train_loss: -3.6636667251586914\n",
            " 48% 999/2078 [00:53<00:56, 19.23it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:02,  9.73it/s]\u001b[A\n",
            " 21% 6/28 [00:03<00:06,  3.39it/s]\u001b[A\n",
            " 50% 14/28 [00:03<00:02,  4.74it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.75it/s]\n",
            "[17:21:30] DeepAR.Eval: - Full test metrics: ND: 0.026; RMSE: 0.063; test_loss: 2.658\n",
            "[17:21:30] DeepAR.Train: train_loss: -1.1514724890391033\n",
            " 96% 2000/2078 [01:48<00:04, 19.09it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:02,  9.52it/s]\u001b[A\n",
            " 32% 9/28 [00:00<00:01, 12.88it/s]\u001b[A\n",
            " 57% 16/28 [00:04<00:02,  4.44it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.39it/s]\n",
            "[17:22:26] DeepAR.Eval: - Full test metrics: ND: 0.030; RMSE: 0.081; test_loss: 2.348\n",
            "[17:22:26] DeepAR.Train: train_loss: -2.980626424153646\n",
            "100% 2078/2078 [01:57<00:00, 17.75it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.36it/s]\n",
            "[17:22:34] DeepAR.Eval: - Full test metrics: ND: 0.045; RMSE: 0.150; test_loss: 2.837\n",
            "[17:22:34] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_13.pth.tar\n",
            "[17:22:34] DeepAR.Train: Current Best ND is: 0.02479\n",
            "[17:22:35] DeepAR.Train: Epoch 15/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:03,  8.43it/s]\u001b[A\n",
            " 25% 7/28 [00:00<00:01, 11.36it/s]\u001b[A\n",
            " 50% 14/28 [00:00<00:00, 15.09it/s]\u001b[A\n",
            " 64% 18/28 [00:04<00:03,  2.80it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.03it/s]\n",
            "[17:22:39] DeepAR.Eval: - Full test metrics: ND: 0.041; RMSE: 0.133; test_loss: 2.577\n",
            "[17:22:39] DeepAR.Train: train_loss: 0.0002733469009399414\n",
            "[17:22:39] DeepAR.Train: train_loss: 0.0002733469009399414\n",
            " 48% 1000/2078 [00:55<00:55, 19.34it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:02,  9.20it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:01, 12.42it/s]\u001b[A\n",
            " 54% 15/28 [00:00<00:00, 16.44it/s]\u001b[A\n",
            " 75% 21/28 [00:00<00:00, 20.98it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.28it/s]\n",
            "[17:23:35] DeepAR.Eval: - Full test metrics: ND: 0.025; RMSE: 0.079; test_loss: 2.352\n",
            "[17:23:35] DeepAR.Train: train_loss: -2.5617284774780273\n",
            " 96% 2000/2078 [01:48<00:04, 18.36it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  7.60it/s]\u001b[A\n",
            " 32% 9/28 [00:00<00:01, 10.38it/s]\u001b[A\n",
            " 46% 13/28 [00:03<00:05,  2.98it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.98it/s]\n",
            "[17:24:27] DeepAR.Eval: - Full test metrics: ND: 0.026; RMSE: 0.067; test_loss: 2.337\n",
            "[17:24:27] DeepAR.Train: train_loss: -3.1163981755574546\n",
            "100% 2078/2078 [01:55<00:00, 17.92it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.74it/s]\n",
            "[17:24:35] DeepAR.Eval: - Full test metrics: ND: 0.028; RMSE: 0.074; test_loss: 2.331\n",
            "[17:24:35] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_14.pth.tar\n",
            "[17:24:35] DeepAR.Train: Current Best ND is: 0.02479\n",
            "[17:24:36] DeepAR.Train: Epoch 16/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:03,  8.43it/s]\u001b[A\n",
            " 32% 9/28 [00:00<00:01, 11.52it/s]\u001b[A\n",
            " 54% 15/28 [00:04<00:03,  3.84it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.38it/s]\n",
            "[17:24:40] DeepAR.Eval: - Full test metrics: ND: 0.030; RMSE: 0.080; test_loss: 2.349\n",
            "[17:24:40] DeepAR.Train: train_loss: -3.437441825866699\n",
            "[17:24:40] DeepAR.Train: train_loss: -3.437441825866699\n",
            " 48% 1000/2078 [00:53<00:54, 19.82it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  8.83it/s]\u001b[A\n",
            " 29% 8/28 [00:04<00:05,  3.97it/s]\u001b[A\n",
            " 57% 16/28 [00:04<00:02,  5.53it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.24it/s]\n",
            "[17:25:33] DeepAR.Eval: - Full test metrics: ND: 0.025; RMSE: 0.063; test_loss: 2.545\n",
            "[17:25:33] DeepAR.Train: train_loss: -2.946685791015625\n",
            " 96% 2000/2078 [01:45<00:03, 24.00it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  7% 2/28 [00:00<00:01, 18.70it/s]\u001b[A\n",
            " 36% 10/28 [00:00<00:00, 24.20it/s]\u001b[A\n",
            " 68% 19/28 [00:03<00:01,  6.54it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.90it/s]\n",
            "[17:26:25] DeepAR.Eval: - Full test metrics: ND: 0.024; RMSE: 0.056; test_loss: 2.161\n",
            "[17:26:25] DeepAR.Train: train_loss: -2.3573878606160483\n",
            "100% 2078/2078 [01:53<00:00, 18.37it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.49it/s]\n",
            "[17:26:33] DeepAR.Eval: - Full test metrics: ND: 0.025; RMSE: 0.064; test_loss: 2.613\n",
            "[17:26:33] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_15.pth.tar\n",
            "[17:26:33] DeepAR.Train: Current Best ND is: 0.02479\n",
            "[17:26:33] DeepAR.Train: Epoch 17/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:03,  8.97it/s]\u001b[A\n",
            " 32% 9/28 [00:00<00:01, 12.17it/s]\u001b[A\n",
            " 57% 16/28 [00:00<00:00, 16.05it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.22it/s]\n",
            "[17:26:38] DeepAR.Eval: - Full test metrics: ND: 0.025; RMSE: 0.062; test_loss: 2.632\n",
            "[17:26:38] DeepAR.Train: train_loss: -3.9152491887410483\n",
            "[17:26:38] DeepAR.Train: train_loss: -3.9152491887410483\n",
            " 48% 999/2078 [00:52<00:46, 23.41it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  7% 2/28 [00:00<00:01, 18.60it/s]\u001b[A\n",
            " 39% 11/28 [00:00<00:00, 24.28it/s]\u001b[A\n",
            " 61% 17/28 [00:04<00:02,  4.57it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.73it/s]\n",
            "[17:27:30] DeepAR.Eval: - Full test metrics: ND: 0.034; RMSE: 0.111; test_loss: 2.383\n",
            "[17:27:30] DeepAR.Train: train_loss: -2.6205747922261557\n",
            " 96% 2000/2078 [01:43<00:03, 19.87it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:02,  9.39it/s]\u001b[A\n",
            " 32% 9/28 [00:00<00:01, 12.72it/s]\u001b[A\n",
            " 57% 16/28 [00:00<00:00, 16.79it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.69it/s]\n",
            "[17:28:22] DeepAR.Eval: - Full test metrics: ND: 0.030; RMSE: 0.088; test_loss: 1.981\n",
            "[17:28:22] DeepAR.Train: train_loss: -2.620173454284668\n",
            "100% 2078/2078 [01:51<00:00, 18.60it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.85it/s]\n",
            "[17:28:29] DeepAR.Eval: - Full test metrics: ND: 0.028; RMSE: 0.078; test_loss: 2.090\n",
            "[17:28:30] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_16.pth.tar\n",
            "[17:28:30] DeepAR.Train: Current Best ND is: 0.02479\n",
            "[17:28:30] DeepAR.Train: Epoch 18/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  7% 2/28 [00:00<00:01, 17.60it/s]\u001b[A\n",
            " 36% 10/28 [00:00<00:00, 22.82it/s]\u001b[A\n",
            " 46% 13/28 [00:04<00:06,  2.42it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.59it/s]\n",
            "[17:28:34] DeepAR.Eval: - Full test metrics: ND: 0.025; RMSE: 0.064; test_loss: 2.014\n",
            "[17:28:34] DeepAR.Train: train_loss: -2.7499621709187827\n",
            "[17:28:34] DeepAR.Train: train_loss: -2.7499621709187827\n",
            " 48% 1000/2078 [00:52<00:53, 20.26it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  8.85it/s]\u001b[A\n",
            " 32% 9/28 [00:00<00:01, 12.05it/s]\u001b[A\n",
            " 46% 13/28 [00:03<00:04,  3.01it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.88it/s]\n",
            "[17:29:26] DeepAR.Eval: - Full test metrics: ND: 0.027; RMSE: 0.076; test_loss: 2.045\n",
            "[17:29:26] DeepAR.Train: train_loss: -3.1501458485921225\n",
            " 96% 1999/2078 [01:43<00:03, 20.12it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  8.74it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:01, 11.85it/s]\u001b[A\n",
            " 54% 15/28 [00:00<00:00, 15.67it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.61it/s]\n",
            "[17:30:18] DeepAR.Eval: - Full test metrics: ND: 0.026; RMSE: 0.067; test_loss: 1.949\n",
            "[17:30:18] DeepAR.Train: train_loss: -3.2460320790608725\n",
            "100% 2078/2078 [01:51<00:00, 18.68it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.64it/s]\n",
            "[17:30:25] DeepAR.Eval: - Full test metrics: ND: 0.024; RMSE: 0.060; test_loss: 1.881\n",
            "[17:30:26] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_17.pth.tar\n",
            "[17:30:26] DeepAR.Utils: Best checkpoint copied to best.pth.tar\n",
            "[17:30:26] DeepAR.Train: - Found new best ND\n",
            "[17:30:26] DeepAR.Train: Current Best ND is: 0.02444\n",
            "[17:30:26] DeepAR.Train: Epoch 19/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:02,  9.26it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:01, 12.50it/s]\u001b[A\n",
            " 54% 15/28 [00:00<00:00, 16.55it/s]\u001b[A\n",
            " 82% 23/28 [00:00<00:00, 21.55it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.30it/s]\n",
            "[17:30:31] DeepAR.Eval: - Full test metrics: ND: 0.024; RMSE: 0.057; test_loss: 1.878\n",
            "[17:30:31] DeepAR.Train: train_loss: -3.5578651428222656\n",
            "[17:30:31] DeepAR.Train: train_loss: -3.5578651428222656\n",
            " 48% 998/2078 [00:52<00:53, 20.12it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  8.63it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:01, 11.67it/s]\u001b[A\n",
            " 57% 16/28 [00:00<00:00, 15.62it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.69it/s]\n",
            "[17:31:23] DeepAR.Eval: - Full test metrics: ND: 0.031; RMSE: 0.088; test_loss: 2.104\n",
            "[17:31:23] DeepAR.Train: train_loss: -2.249138832092285\n",
            " 96% 1999/2078 [01:43<00:03, 22.68it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            " 11% 3/28 [00:00<00:00, 27.51it/s]\u001b[A\n",
            " 46% 13/28 [00:00<00:00, 34.83it/s]\u001b[A\n",
            " 61% 17/28 [00:03<00:03,  3.43it/s]\u001b[A\n",
            "100% 28/28 [00:03<00:00,  7.04it/s]\n",
            "[17:32:13] DeepAR.Eval: - Full test metrics: ND: 0.024; RMSE: 0.061; test_loss: 2.143\n",
            "[17:32:13] DeepAR.Train: train_loss: -2.9130662282307944\n",
            "100% 2078/2078 [01:50<00:00, 18.75it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.42it/s]\n",
            "[17:32:21] DeepAR.Eval: - Full test metrics: ND: 0.024; RMSE: 0.059; test_loss: 2.042\n",
            "[17:32:21] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_18.pth.tar\n",
            "[17:32:21] DeepAR.Utils: Best checkpoint copied to best.pth.tar\n",
            "[17:32:21] DeepAR.Train: - Found new best ND\n",
            "[17:32:21] DeepAR.Train: Current Best ND is: 0.02414\n",
            "[17:32:22] DeepAR.Train: Epoch 20/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:19,  1.39it/s]\u001b[A\n",
            " 11% 3/28 [00:00<00:13,  1.85it/s]\u001b[A\n",
            " 18% 5/28 [00:04<00:21,  1.06it/s]\u001b[A\n",
            " 50% 14/28 [00:04<00:09,  1.50it/s]\u001b[A\n",
            " 75% 21/28 [00:04<00:03,  2.12it/s]\u001b[A\n",
            "100% 28/28 [00:05<00:00,  5.47it/s]\n",
            "[17:32:27] DeepAR.Eval: - Full test metrics: ND: 0.025; RMSE: 0.066; test_loss: 2.045\n",
            "[17:32:27] DeepAR.Train: train_loss: -3.8676748275756836\n",
            "[17:32:27] DeepAR.Train: train_loss: -3.8676748275756836\n",
            " 48% 998/2078 [00:52<00:53, 20.18it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:02,  9.47it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:01, 12.75it/s]\u001b[A\n",
            " 46% 13/28 [00:04<00:04,  3.50it/s]\u001b[A\n",
            " 71% 20/28 [00:04<00:01,  4.89it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.50it/s]\n",
            "[17:33:18] DeepAR.Eval: - Full test metrics: ND: 0.027; RMSE: 0.076; test_loss: 1.911\n",
            "[17:33:18] DeepAR.Train: train_loss: -3.186240832010905\n",
            " 96% 1999/2078 [01:44<00:04, 17.58it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  8.91it/s]\u001b[A\n",
            " 11% 3/28 [00:03<00:16,  1.54it/s]\u001b[A\n",
            " 43% 12/28 [00:04<00:07,  2.19it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.63it/s]\n",
            "[17:34:11] DeepAR.Eval: - Full test metrics: ND: 0.025; RMSE: 0.064; test_loss: 1.945\n",
            "[17:34:11] DeepAR.Train: train_loss: -3.441714286804199\n",
            "100% 2078/2078 [01:52<00:00, 18.44it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.47it/s]\n",
            "[17:34:19] DeepAR.Eval: - Full test metrics: ND: 0.023; RMSE: 0.056; test_loss: 1.920\n",
            "[17:34:19] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_19.pth.tar\n",
            "[17:34:19] DeepAR.Utils: Best checkpoint copied to best.pth.tar\n",
            "[17:34:19] DeepAR.Train: - Found new best ND\n",
            "[17:34:19] DeepAR.Train: Current Best ND is: 0.02298\n",
            "[17:34:19] DeepAR.Train: Epoch 21/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  7% 2/28 [00:00<00:01, 19.81it/s]\u001b[A\n",
            " 36% 10/28 [00:00<00:00, 25.32it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.76it/s]\n",
            "[17:34:24] DeepAR.Eval: - Full test metrics: ND: 0.023; RMSE: 0.055; test_loss: 1.921\n",
            "[17:34:24] DeepAR.Train: train_loss: -3.1799338658650718\n",
            "[17:34:24] DeepAR.Train: train_loss: -3.1799338658650718\n",
            " 48% 999/2078 [00:54<00:57, 18.82it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  8.99it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:01, 12.11it/s]\u001b[A\n",
            " 61% 17/28 [00:00<00:00, 16.26it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.96it/s]\n",
            "[17:35:18] DeepAR.Eval: - Full test metrics: ND: 0.026; RMSE: 0.075; test_loss: 2.196\n",
            "[17:35:18] DeepAR.Train: train_loss: -3.203730583190918\n",
            " 96% 2000/2078 [01:46<00:03, 19.55it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  7.76it/s]\u001b[A\n",
            " 36% 10/28 [00:00<00:01, 10.64it/s]\u001b[A\n",
            " 57% 16/28 [00:00<00:00, 13.99it/s]\u001b[A\n",
            " 82% 23/28 [00:00<00:00, 18.37it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.78it/s]\n",
            "[17:36:10] DeepAR.Eval: - Full test metrics: ND: 0.024; RMSE: 0.062; test_loss: 1.804\n",
            "[17:36:10] DeepAR.Train: train_loss: -3.0291620890299478\n",
            "100% 2078/2078 [01:54<00:00, 18.09it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.30it/s]\n",
            "[17:36:19] DeepAR.Eval: - Full test metrics: ND: 0.026; RMSE: 0.076; test_loss: 1.999\n",
            "[17:36:19] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_20.pth.tar\n",
            "[17:36:19] DeepAR.Train: Current Best ND is: 0.02298\n",
            "[17:36:19] DeepAR.Train: Epoch 22/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:02,  9.12it/s]\u001b[A\n",
            "  7% 2/28 [00:04<00:33,  1.30s/it]\u001b[A\n",
            " 36% 10/28 [00:04<00:16,  1.09it/s]\u001b[A\n",
            " 61% 17/28 [00:04<00:07,  1.55it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.10it/s]\n",
            "[17:36:24] DeepAR.Eval: - Full test metrics: ND: 0.027; RMSE: 0.077; test_loss: 2.003\n",
            "[17:36:24] DeepAR.Train: train_loss: -3.284830411275228\n",
            "[17:36:24] DeepAR.Train: train_loss: -3.284830411275228\n",
            " 48% 1000/2078 [00:53<00:51, 20.82it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:02,  9.01it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:01, 12.13it/s]\u001b[A\n",
            " 54% 15/28 [00:00<00:00, 16.11it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.86it/s]\n",
            "[17:37:17] DeepAR.Eval: - Full test metrics: ND: 0.025; RMSE: 0.068; test_loss: 1.990\n",
            "[17:37:17] DeepAR.Train: train_loss: -3.3914788564046225\n",
            " 96% 1999/2078 [01:47<00:04, 19.44it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  8.76it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:01, 11.84it/s]\u001b[A\n",
            " 50% 14/28 [00:04<00:03,  3.96it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.52it/s]\n",
            "[17:38:11] DeepAR.Eval: - Full test metrics: ND: 0.028; RMSE: 0.072; test_loss: 1.768\n",
            "[17:38:11] DeepAR.Train: train_loss: -3.2037175496419272\n",
            "100% 2078/2078 [01:55<00:00, 17.94it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.44it/s]\n",
            "[17:38:19] DeepAR.Eval: - Full test metrics: ND: 0.025; RMSE: 0.068; test_loss: 1.753\n",
            "[17:38:20] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_21.pth.tar\n",
            "[17:38:20] DeepAR.Train: Current Best ND is: 0.02298\n",
            "[17:38:20] DeepAR.Train: Epoch 23/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  7% 2/28 [00:00<00:01, 16.29it/s]\u001b[A\n",
            " 29% 8/28 [00:04<00:04,  4.01it/s]\u001b[A\n",
            " 57% 16/28 [00:04<00:02,  5.60it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.16it/s]\n",
            "[17:38:25] DeepAR.Eval: - Full test metrics: ND: 0.026; RMSE: 0.071; test_loss: 1.749\n",
            "[17:38:25] DeepAR.Train: train_loss: -3.10026486714681\n",
            "[17:38:25] DeepAR.Train: train_loss: -3.10026486714681\n",
            " 48% 999/2078 [00:55<00:56, 19.21it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  7.44it/s]\u001b[A\n",
            " 32% 9/28 [00:00<00:01, 10.19it/s]\u001b[A\n",
            " 61% 17/28 [00:00<00:00, 13.73it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.71it/s]\n",
            "[17:39:19] DeepAR.Eval: - Full test metrics: ND: 0.028; RMSE: 0.085; test_loss: 1.806\n",
            "[17:39:19] DeepAR.Train: train_loss: -3.5377410252889\n",
            " 96% 2000/2078 [01:49<00:03, 19.83it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  7.29it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:02,  9.96it/s]\u001b[A\n",
            " 54% 15/28 [00:04<00:03,  4.24it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.54it/s]\n",
            "[17:40:13] DeepAR.Eval: - Full test metrics: ND: 0.026; RMSE: 0.070; test_loss: 1.755\n",
            "[17:40:13] DeepAR.Train: train_loss: -3.876478830973307\n",
            "100% 2078/2078 [01:57<00:00, 17.74it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.82it/s]\n",
            "[17:40:21] DeepAR.Eval: - Full test metrics: ND: 0.029; RMSE: 0.082; test_loss: 1.820\n",
            "[17:40:21] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_22.pth.tar\n",
            "[17:40:21] DeepAR.Train: Current Best ND is: 0.02298\n",
            "[17:40:22] DeepAR.Train: Epoch 24/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:03,  8.66it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:01, 11.70it/s]\u001b[A\n",
            " 54% 15/28 [00:00<00:00, 15.54it/s]\u001b[A\n",
            " 79% 22/28 [00:00<00:00, 20.17it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.08it/s]\n",
            "[17:40:26] DeepAR.Eval: - Full test metrics: ND: 0.031; RMSE: 0.088; test_loss: 1.839\n",
            "[17:40:26] DeepAR.Train: train_loss: -2.6603477795918784\n",
            "[17:40:26] DeepAR.Train: train_loss: -2.6603477795918784\n",
            " 48% 998/2078 [00:54<00:47, 22.73it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  7% 2/28 [00:00<00:01, 18.99it/s]\u001b[A\n",
            " 39% 11/28 [00:00<00:00, 24.77it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.64it/s]\n",
            "[17:41:20] DeepAR.Eval: - Full test metrics: ND: 0.026; RMSE: 0.069; test_loss: 1.892\n",
            "[17:41:20] DeepAR.Train: train_loss: -2.756972312927246\n",
            " 96% 1999/2078 [01:48<00:03, 20.26it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  8.11it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:01, 11.01it/s]\u001b[A\n",
            " 54% 15/28 [00:04<00:02,  4.40it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.64it/s]\n",
            "[17:42:14] DeepAR.Eval: - Full test metrics: ND: 0.024; RMSE: 0.062; test_loss: 1.793\n",
            "[17:42:14] DeepAR.Train: train_loss: -3.5295890172322593\n",
            "100% 2078/2078 [01:56<00:00, 17.81it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.83it/s]\n",
            "[17:42:22] DeepAR.Eval: - Full test metrics: ND: 0.027; RMSE: 0.078; test_loss: 1.764\n",
            "[17:42:23] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_23.pth.tar\n",
            "[17:42:23] DeepAR.Train: Current Best ND is: 0.02298\n",
            "[17:42:23] DeepAR.Train: Epoch 25/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  7% 2/28 [00:00<00:01, 17.08it/s]\u001b[A\n",
            " 29% 8/28 [00:03<00:04,  4.27it/s]\u001b[A\n",
            " 61% 17/28 [00:04<00:01,  5.98it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.61it/s]\n",
            "[17:42:27] DeepAR.Eval: - Full test metrics: ND: 0.027; RMSE: 0.079; test_loss: 1.766\n",
            "[17:42:27] DeepAR.Train: train_loss: -2.13162628809611\n",
            "[17:42:27] DeepAR.Train: train_loss: -2.13162628809611\n",
            " 48% 1000/2078 [00:55<00:57, 18.90it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:02,  9.54it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:01, 12.86it/s]\u001b[A\n",
            " 54% 15/28 [00:03<00:02,  4.62it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.73it/s]\n",
            "[17:43:23] DeepAR.Eval: - Full test metrics: ND: 0.027; RMSE: 0.079; test_loss: 1.712\n",
            "[17:43:23] DeepAR.Train: train_loss: -3.030231475830078\n",
            " 96% 1998/2078 [01:50<00:03, 23.77it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            " 11% 3/28 [00:00<00:00, 25.52it/s]\u001b[A\n",
            " 39% 11/28 [00:00<00:00, 31.93it/s]\u001b[A\n",
            " 54% 15/28 [00:03<00:03,  3.41it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.97it/s]\n",
            "[17:44:17] DeepAR.Eval: - Full test metrics: ND: 0.026; RMSE: 0.073; test_loss: 1.695\n",
            "[17:44:17] DeepAR.Train: train_loss: -3.0337823232014975\n",
            "100% 2078/2078 [01:58<00:00, 17.58it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.29it/s]\n",
            "[17:44:26] DeepAR.Eval: - Full test metrics: ND: 0.025; RMSE: 0.072; test_loss: 1.744\n",
            "[17:44:26] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_24.pth.tar\n",
            "[17:44:26] DeepAR.Train: Current Best ND is: 0.02298\n",
            "[17:44:26] DeepAR.Train: Epoch 26/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            " 11% 3/28 [00:00<00:01, 24.92it/s]\u001b[A\n",
            " 36% 10/28 [00:04<00:03,  5.07it/s]\u001b[A\n",
            " 64% 18/28 [00:04<00:01,  7.03it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.44it/s]\n",
            "[17:44:31] DeepAR.Eval: - Full test metrics: ND: 0.024; RMSE: 0.069; test_loss: 1.744\n",
            "[17:44:31] DeepAR.Train: train_loss: -3.3201398849487305\n",
            "[17:44:31] DeepAR.Train: train_loss: -3.3201398849487305\n",
            " 48% 1000/2078 [00:54<00:55, 19.48it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  8.37it/s]\u001b[A\n",
            " 25% 7/28 [00:04<00:05,  3.57it/s]\u001b[A\n",
            " 57% 16/28 [00:04<00:02,  5.01it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.47it/s]\n",
            "[17:45:25] DeepAR.Eval: - Full test metrics: ND: 0.024; RMSE: 0.063; test_loss: 1.696\n",
            "[17:45:25] DeepAR.Train: train_loss: -3.627892812093099\n",
            " 96% 1998/2078 [01:46<00:03, 24.36it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  7% 2/28 [00:03<00:47,  1.83s/it]\u001b[A\n",
            " 39% 11/28 [00:03<00:21,  1.28s/it]\u001b[A\n",
            "100% 28/28 [00:03<00:00,  7.01it/s]\n",
            "[17:46:16] DeepAR.Eval: - Full test metrics: ND: 0.023; RMSE: 0.059; test_loss: 1.679\n",
            "[17:46:16] DeepAR.Train: train_loss: -3.5171197255452475\n",
            "100% 2078/2078 [01:54<00:00, 18.18it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.55it/s]\n",
            "[17:46:25] DeepAR.Eval: - Full test metrics: ND: 0.023; RMSE: 0.058; test_loss: 1.809\n",
            "[17:46:25] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_25.pth.tar\n",
            "[17:46:25] DeepAR.Utils: Best checkpoint copied to best.pth.tar\n",
            "[17:46:25] DeepAR.Train: - Found new best ND\n",
            "[17:46:25] DeepAR.Train: Current Best ND is: 0.02263\n",
            "[17:46:26] DeepAR.Train: Epoch 27/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:03,  8.33it/s]\u001b[A\n",
            "  7% 2/28 [00:03<00:32,  1.25s/it]\u001b[A\n",
            " 39% 11/28 [00:04<00:14,  1.14it/s]\u001b[A\n",
            " 71% 20/28 [00:04<00:04,  1.62it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.44it/s]\n",
            "[17:46:30] DeepAR.Eval: - Full test metrics: ND: 0.023; RMSE: 0.059; test_loss: 1.796\n",
            "[17:46:30] DeepAR.Train: train_loss: -2.104612350463867\n",
            "[17:46:30] DeepAR.Train: train_loss: -2.104612350463867\n",
            " 48% 1000/2078 [00:56<00:59, 18.05it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:02,  9.26it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:01, 12.51it/s]\u001b[A\n",
            " 50% 14/28 [00:00<00:00, 16.36it/s]\u001b[A\n",
            " 75% 21/28 [00:00<00:00, 21.14it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.55it/s]\n",
            "[17:47:26] DeepAR.Eval: - Full test metrics: ND: 0.024; RMSE: 0.063; test_loss: 1.663\n",
            "[17:47:26] DeepAR.Train: train_loss: -3.6197179158528647\n",
            " 96% 1999/2078 [01:50<00:04, 18.85it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  8.99it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:01, 12.15it/s]\u001b[A\n",
            " 54% 15/28 [00:00<00:00, 16.07it/s]\u001b[A\n",
            " 68% 19/28 [00:04<00:02,  3.05it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.57it/s]\n",
            "[17:48:21] DeepAR.Eval: - Full test metrics: ND: 0.030; RMSE: 0.094; test_loss: 1.777\n",
            "[17:48:21] DeepAR.Train: train_loss: -2.1458541552225747\n",
            "100% 2078/2078 [01:58<00:00, 17.51it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.35it/s]\n",
            "[17:48:29] DeepAR.Eval: - Full test metrics: ND: 0.041; RMSE: 0.146; test_loss: 1.949\n",
            "[17:48:29] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_26.pth.tar\n",
            "[17:48:29] DeepAR.Train: Current Best ND is: 0.02263\n",
            "[17:48:29] DeepAR.Train: Epoch 28/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:02,  9.05it/s]\u001b[A\n",
            " 14% 4/28 [00:04<00:12,  1.97it/s]\u001b[A\n",
            " 43% 12/28 [00:04<00:05,  2.78it/s]\u001b[A\n",
            " 64% 18/28 [00:04<00:02,  3.90it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  5.81it/s]\n",
            "[17:48:34] DeepAR.Eval: - Full test metrics: ND: 0.040; RMSE: 0.144; test_loss: 1.890\n",
            "[17:48:34] DeepAR.Train: train_loss: -2.879147211710612\n",
            "[17:48:34] DeepAR.Train: train_loss: -2.879147211710612\n",
            " 48% 999/2078 [00:56<00:50, 21.46it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  7.51it/s]\u001b[A\n",
            " 32% 9/28 [00:00<00:01, 10.24it/s]\u001b[A\n",
            " 43% 12/28 [00:04<00:07,  2.16it/s]\u001b[A\n",
            " 68% 19/28 [00:04<00:02,  3.04it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.30it/s]\n",
            "[17:49:30] DeepAR.Eval: - Full test metrics: ND: 0.024; RMSE: 0.065; test_loss: 1.741\n",
            "[17:49:30] DeepAR.Train: train_loss: -3.731664021809896\n",
            " 96% 2000/2078 [01:50<00:04, 18.55it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:02,  9.41it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:01, 12.64it/s]\u001b[A\n",
            " 43% 12/28 [00:03<00:05,  3.05it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.89it/s]\n",
            "[17:50:24] DeepAR.Eval: - Full test metrics: ND: 0.028; RMSE: 0.078; test_loss: 1.777\n",
            "[17:50:24] DeepAR.Train: train_loss: -2.7072184880574546\n",
            "100% 2078/2078 [01:59<00:00, 17.43it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.14it/s]\n",
            "[17:50:33] DeepAR.Eval: - Full test metrics: ND: 0.028; RMSE: 0.073; test_loss: 1.702\n",
            "[17:50:33] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_27.pth.tar\n",
            "[17:50:33] DeepAR.Train: Current Best ND is: 0.02263\n",
            "[17:50:33] DeepAR.Train: Epoch 29/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:14,  1.83it/s]\u001b[A\n",
            " 11% 3/28 [00:00<00:10,  2.36it/s]\u001b[A\n",
            " 39% 11/28 [00:00<00:05,  3.32it/s]\u001b[A\n",
            " 50% 14/28 [00:04<00:08,  1.67it/s]\u001b[A\n",
            "100% 28/28 [00:05<00:00,  5.56it/s]\n",
            "[17:50:39] DeepAR.Eval: - Full test metrics: ND: 0.029; RMSE: 0.077; test_loss: 1.700\n",
            "[17:50:39] DeepAR.Train: train_loss: -2.1220788955688477\n",
            "[17:50:39] DeepAR.Train: train_loss: -2.1220788955688477\n",
            " 48% 1000/2078 [00:55<00:44, 23.99it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  7% 2/28 [00:00<00:01, 17.82it/s]\u001b[A\n",
            " 36% 10/28 [00:00<00:00, 23.24it/s]\u001b[A\n",
            " 68% 19/28 [00:00<00:00, 29.43it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.94it/s]\n",
            "[17:51:33] DeepAR.Eval: - Full test metrics: ND: 0.026; RMSE: 0.070; test_loss: 1.721\n",
            "[17:51:33] DeepAR.Train: train_loss: -3.107158660888672\n",
            " 96% 2000/2078 [01:50<00:04, 17.42it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  8.27it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:01, 11.24it/s]\u001b[A\n",
            " 54% 15/28 [00:00<00:00, 14.93it/s]\u001b[A\n",
            " 68% 19/28 [00:04<00:02,  3.03it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.63it/s]\n",
            "[17:52:29] DeepAR.Eval: - Full test metrics: ND: 0.027; RMSE: 0.084; test_loss: 1.754\n",
            "[17:52:29] DeepAR.Train: train_loss: -3.094027837117513\n",
            "100% 2078/2078 [01:59<00:00, 17.41it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.41it/s]\n",
            "[17:52:37] DeepAR.Eval: - Full test metrics: ND: 0.029; RMSE: 0.077; test_loss: 1.770\n",
            "[17:52:37] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_28.pth.tar\n",
            "[17:52:37] DeepAR.Train: Current Best ND is: 0.02263\n",
            "[17:52:38] DeepAR.Train: Epoch 30/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  7% 2/28 [00:00<00:01, 16.96it/s]\u001b[A\n",
            " 39% 11/28 [00:00<00:00, 22.37it/s]\u001b[A\n",
            " 68% 19/28 [00:00<00:00, 28.38it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.46it/s]\n",
            "[17:52:42] DeepAR.Eval: - Full test metrics: ND: 0.031; RMSE: 0.083; test_loss: 1.793\n",
            "[17:52:42] DeepAR.Train: train_loss: -3.996837933858236\n",
            "[17:52:42] DeepAR.Train: train_loss: -3.996837933858236\n",
            " 48% 1000/2078 [00:56<00:57, 18.84it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  6.76it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:02,  9.26it/s]\u001b[A\n",
            " 39% 11/28 [00:04<00:07,  2.15it/s]\u001b[A\n",
            " 68% 19/28 [00:04<00:02,  3.03it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.35it/s]\n",
            "[17:53:39] DeepAR.Eval: - Full test metrics: ND: 0.027; RMSE: 0.079; test_loss: 1.713\n",
            "[17:53:39] DeepAR.Train: train_loss: -3.4025046030680337\n",
            " 96% 2000/2078 [01:51<00:04, 18.74it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:02,  9.03it/s]\u001b[A\n",
            " 25% 7/28 [00:00<00:01, 12.04it/s]\u001b[A\n",
            " 36% 10/28 [00:03<00:07,  2.38it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.84it/s]\n",
            "[17:54:33] DeepAR.Eval: - Full test metrics: ND: 0.026; RMSE: 0.071; test_loss: 1.734\n",
            "[17:54:33] DeepAR.Train: train_loss: -3.253119786580404\n",
            "100% 2078/2078 [01:59<00:00, 17.46it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.97it/s]\n",
            "[17:54:41] DeepAR.Eval: - Full test metrics: ND: 0.025; RMSE: 0.068; test_loss: 1.744\n",
            "[17:54:41] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_29.pth.tar\n",
            "[17:54:41] DeepAR.Train: Current Best ND is: 0.02263\n",
            "[17:54:41] DeepAR.Train: Epoch 31/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  7% 2/28 [00:00<00:01, 18.46it/s]\u001b[A\n",
            " 39% 11/28 [00:00<00:00, 24.05it/s]\u001b[A\n",
            " 68% 19/28 [00:00<00:00, 30.11it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.56it/s]\n",
            "[17:54:46] DeepAR.Eval: - Full test metrics: ND: 0.024; RMSE: 0.064; test_loss: 1.751\n",
            "[17:54:46] DeepAR.Train: train_loss: -2.830433209737142\n",
            "[17:54:46] DeepAR.Train: train_loss: -2.830433209737142\n",
            " 48% 999/2078 [00:55<01:00, 17.89it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  8.99it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:01, 12.10it/s]\u001b[A\n",
            " 57% 16/28 [00:00<00:00, 16.10it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.57it/s]\n",
            "[17:55:41] DeepAR.Eval: - Full test metrics: ND: 0.027; RMSE: 0.082; test_loss: 1.596\n",
            "[17:55:41] DeepAR.Train: train_loss: -3.7623751958211265\n",
            " 96% 2000/2078 [01:51<00:04, 18.64it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  7.08it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:02,  9.69it/s]\u001b[A\n",
            " 54% 15/28 [00:04<00:03,  4.20it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.49it/s]\n",
            "[17:56:37] DeepAR.Eval: - Full test metrics: ND: 0.024; RMSE: 0.064; test_loss: 1.609\n",
            "[17:56:37] DeepAR.Train: train_loss: -4.210737546284993\n",
            "100% 2078/2078 [01:59<00:00, 17.38it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.20it/s]\n",
            "[17:56:45] DeepAR.Eval: - Full test metrics: ND: 0.025; RMSE: 0.071; test_loss: 1.569\n",
            "[17:56:46] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_30.pth.tar\n",
            "[17:56:46] DeepAR.Train: Current Best ND is: 0.02263\n",
            "[17:56:46] DeepAR.Train: Epoch 32/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  7% 2/28 [00:00<00:01, 16.14it/s]\u001b[A\n",
            " 14% 4/28 [00:04<00:15,  1.52it/s]\u001b[A\n",
            " 50% 14/28 [00:04<00:06,  2.15it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.20it/s]\n",
            "[17:56:51] DeepAR.Eval: - Full test metrics: ND: 0.025; RMSE: 0.069; test_loss: 1.578\n",
            "[17:56:51] DeepAR.Train: train_loss: -3.518731435139974\n",
            "[17:56:51] DeepAR.Train: train_loss: -3.518731435139974\n",
            " 48% 1000/2078 [00:55<00:45, 23.52it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  7% 2/28 [00:00<00:01, 19.46it/s]\u001b[A\n",
            " 36% 10/28 [00:00<00:00, 24.95it/s]\u001b[A\n",
            " 61% 17/28 [00:00<00:00, 30.55it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.80it/s]\n",
            "[17:57:45] DeepAR.Eval: - Full test metrics: ND: 0.025; RMSE: 0.067; test_loss: 1.630\n",
            "[17:57:45] DeepAR.Train: train_loss: -3.088428497314453\n",
            " 96% 1999/2078 [01:52<00:04, 18.06it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  7.89it/s]\u001b[A\n",
            " 18% 5/28 [00:04<00:08,  2.58it/s]\u001b[A\n",
            " 46% 13/28 [00:04<00:04,  3.63it/s]\u001b[A\n",
            " 75% 21/28 [00:04<00:01,  5.08it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.26it/s]\n",
            "[17:58:43] DeepAR.Eval: - Full test metrics: ND: 0.033; RMSE: 0.094; test_loss: 1.664\n",
            "[17:58:43] DeepAR.Train: train_loss: -2.50688107808431\n",
            "100% 2078/2078 [02:01<00:00, 17.17it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.20it/s]\n",
            "[17:58:51] DeepAR.Eval: - Full test metrics: ND: 0.029; RMSE: 0.075; test_loss: 1.806\n",
            "[17:58:52] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_31.pth.tar\n",
            "[17:58:52] DeepAR.Train: Current Best ND is: 0.02263\n",
            "[17:58:52] DeepAR.Train: Epoch 33/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:03,  7.85it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:01, 10.62it/s]\u001b[A\n",
            " 39% 11/28 [00:04<00:07,  2.17it/s]\u001b[A\n",
            " 68% 19/28 [00:04<00:02,  3.06it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.27it/s]\n",
            "[17:58:57] DeepAR.Eval: - Full test metrics: ND: 0.031; RMSE: 0.080; test_loss: 1.804\n",
            "[17:58:57] DeepAR.Train: train_loss: -3.4689308802286782\n",
            "[17:58:57] DeepAR.Train: train_loss: -3.4689308802286782\n",
            " 48% 1000/2078 [00:56<00:58, 18.38it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  7.88it/s]\u001b[A\n",
            " 32% 9/28 [00:00<00:01, 10.74it/s]\u001b[A\n",
            " 61% 17/28 [00:00<00:00, 14.44it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.93it/s]\n",
            "[17:59:52] DeepAR.Eval: - Full test metrics: ND: 0.024; RMSE: 0.068; test_loss: 1.670\n",
            "[17:59:52] DeepAR.Train: train_loss: -3.334535280863444\n",
            " 96% 2000/2078 [01:50<00:04, 17.97it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  8.46it/s]\u001b[A\n",
            " 21% 6/28 [00:04<00:06,  3.16it/s]\u001b[A\n",
            " 54% 15/28 [00:04<00:02,  4.44it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.50it/s]\n",
            "[18:00:47] DeepAR.Eval: - Full test metrics: ND: 0.025; RMSE: 0.066; test_loss: 1.596\n",
            "[18:00:47] DeepAR.Train: train_loss: -3.709506352742513\n",
            "100% 2078/2078 [01:59<00:00, 17.40it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.23it/s]\n",
            "[18:00:56] DeepAR.Eval: - Full test metrics: ND: 0.029; RMSE: 0.093; test_loss: 1.587\n",
            "[18:00:56] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_32.pth.tar\n",
            "[18:00:56] DeepAR.Train: Current Best ND is: 0.02263\n",
            "[18:00:56] DeepAR.Train: Epoch 34/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  7% 2/28 [00:00<00:01, 18.36it/s]\u001b[A\n",
            " 39% 11/28 [00:03<00:02,  6.00it/s]\u001b[A\n",
            " 68% 19/28 [00:04<00:01,  8.29it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.64it/s]\n",
            "[18:01:01] DeepAR.Eval: - Full test metrics: ND: 0.028; RMSE: 0.092; test_loss: 1.585\n",
            "[18:01:01] DeepAR.Train: train_loss: -3.300847371419271\n",
            "[18:01:01] DeepAR.Train: train_loss: -3.300847371419271\n",
            " 48% 998/2078 [00:55<00:57, 18.87it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  7% 2/28 [00:00<00:01, 18.78it/s]\u001b[A\n",
            " 36% 10/28 [00:00<00:00, 24.16it/s]\u001b[A\n",
            " 64% 18/28 [00:00<00:00, 30.43it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.98it/s]\n",
            "[18:01:57] DeepAR.Eval: - Full test metrics: ND: 0.029; RMSE: 0.079; test_loss: 1.580\n",
            "[18:01:57] DeepAR.Train: train_loss: -3.4950440724690757\n",
            " 96% 2000/2078 [01:52<00:03, 22.06it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  8.93it/s]\u001b[A\n",
            " 25% 7/28 [00:00<00:01, 11.98it/s]\u001b[A\n",
            " 50% 14/28 [00:00<00:00, 15.92it/s]\u001b[A\n",
            " 75% 21/28 [00:00<00:00, 20.61it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.43it/s]\n",
            "[18:02:53] DeepAR.Eval: - Full test metrics: ND: 0.031; RMSE: 0.079; test_loss: 1.669\n",
            "[18:02:53] DeepAR.Train: train_loss: -3.1864296595255532\n",
            "100% 2078/2078 [02:00<00:00, 17.22it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.81it/s]\n",
            "[18:03:01] DeepAR.Eval: - Full test metrics: ND: 0.024; RMSE: 0.066; test_loss: 1.620\n",
            "[18:03:02] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_33.pth.tar\n",
            "[18:03:02] DeepAR.Train: Current Best ND is: 0.02263\n",
            "[18:03:02] DeepAR.Train: Epoch 35/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:03,  7.16it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:02,  9.76it/s]\u001b[A\n",
            " 57% 16/28 [00:00<00:00, 13.18it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  5.93it/s]\n",
            "[18:03:07] DeepAR.Eval: - Full test metrics: ND: 0.026; RMSE: 0.072; test_loss: 1.597\n",
            "[18:03:07] DeepAR.Train: train_loss: -2.7264092763264975\n",
            "[18:03:07] DeepAR.Train: train_loss: -2.7264092763264975\n",
            " 48% 999/2078 [00:57<00:55, 19.33it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  8.28it/s]\u001b[A\n",
            " 18% 5/28 [00:03<00:08,  2.68it/s]\u001b[A\n",
            " 50% 14/28 [00:04<00:03,  3.77it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.54it/s]\n",
            "[18:04:04] DeepAR.Eval: - Full test metrics: ND: 0.025; RMSE: 0.067; test_loss: 1.706\n",
            "[18:04:04] DeepAR.Train: train_loss: -2.392122427622477\n",
            " 96% 2000/2078 [01:52<00:03, 20.00it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  7% 2/28 [00:00<00:01, 18.59it/s]\u001b[A\n",
            " 18% 5/28 [00:03<00:09,  2.40it/s]\u001b[A\n",
            " 46% 13/28 [00:04<00:04,  3.38it/s]\u001b[A\n",
            " 71% 20/28 [00:04<00:01,  4.72it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.55it/s]\n",
            "[18:04:59] DeepAR.Eval: - Full test metrics: ND: 0.023; RMSE: 0.061; test_loss: 1.679\n",
            "[18:04:59] DeepAR.Train: train_loss: -2.922847112019857\n",
            "100% 2078/2078 [02:01<00:00, 17.08it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.55it/s]\n",
            "[18:05:08] DeepAR.Eval: - Full test metrics: ND: 0.024; RMSE: 0.063; test_loss: 1.628\n",
            "[18:05:08] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_34.pth.tar\n",
            "[18:05:08] DeepAR.Train: Current Best ND is: 0.02263\n",
            "[18:05:09] DeepAR.Train: Epoch 36/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:03,  7.44it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:01, 10.11it/s]\u001b[A\n",
            " 50% 14/28 [00:00<00:01, 13.39it/s]\u001b[A\n",
            " 75% 21/28 [00:00<00:00, 17.55it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.09it/s]\n",
            "[18:05:13] DeepAR.Eval: - Full test metrics: ND: 0.023; RMSE: 0.060; test_loss: 1.642\n",
            "[18:05:13] DeepAR.Train: train_loss: -3.4757630030314126\n",
            "[18:05:13] DeepAR.Train: train_loss: -3.4757630030314126\n",
            " 48% 1000/2078 [01:00<01:04, 16.60it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  7.47it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:01, 10.19it/s]\u001b[A\n",
            " 54% 15/28 [00:04<00:03,  4.23it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.43it/s]\n",
            "[18:06:14] DeepAR.Eval: - Full test metrics: ND: 0.022; RMSE: 0.056; test_loss: 1.686\n",
            "[18:06:14] DeepAR.Train: train_loss: -3.745899518330892\n",
            " 96% 1999/2078 [01:55<00:04, 18.13it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:02,  9.50it/s]\u001b[A\n",
            " 32% 9/28 [00:00<00:01, 12.89it/s]\u001b[A\n",
            " 43% 12/28 [00:03<00:06,  2.32it/s]\u001b[A\n",
            " 68% 19/28 [00:04<00:02,  3.26it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.56it/s]\n",
            "[18:07:09] DeepAR.Eval: - Full test metrics: ND: 0.029; RMSE: 0.085; test_loss: 1.553\n",
            "[18:07:09] DeepAR.Train: train_loss: -3.562380790710449\n",
            "100% 2078/2078 [02:04<00:00, 16.70it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.37it/s]\n",
            "[18:07:18] DeepAR.Eval: - Full test metrics: ND: 0.023; RMSE: 0.059; test_loss: 1.549\n",
            "[18:07:18] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_35.pth.tar\n",
            "[18:07:18] DeepAR.Train: Current Best ND is: 0.02263\n",
            "[18:07:18] DeepAR.Train: Epoch 37/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  7% 2/28 [00:00<00:01, 18.47it/s]\u001b[A\n",
            " 18% 5/28 [00:04<00:10,  2.25it/s]\u001b[A\n",
            " 50% 14/28 [00:04<00:04,  3.18it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.24it/s]\n",
            "[18:07:23] DeepAR.Eval: - Full test metrics: ND: 0.023; RMSE: 0.060; test_loss: 1.548\n",
            "[18:07:23] DeepAR.Train: train_loss: -3.6143821080525718\n",
            "[18:07:23] DeepAR.Train: train_loss: -3.6143821080525718\n",
            " 48% 999/2078 [00:57<00:47, 22.94it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  7% 2/28 [00:00<00:01, 17.82it/s]\u001b[A\n",
            " 36% 10/28 [00:00<00:00, 22.99it/s]\u001b[A\n",
            " 64% 18/28 [00:00<00:00, 29.16it/s]\u001b[A\n",
            "100% 28/28 [00:03<00:00,  7.09it/s]\n",
            "[18:08:19] DeepAR.Eval: - Full test metrics: ND: 0.032; RMSE: 0.098; test_loss: 1.619\n",
            "[18:08:19] DeepAR.Train: train_loss: -3.3041556676228843\n",
            " 96% 1999/2078 [01:53<00:04, 18.23it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  8.43it/s]\u001b[A\n",
            " 21% 6/28 [00:00<00:01, 11.22it/s]\u001b[A\n",
            " 46% 13/28 [00:00<00:01, 14.95it/s]\u001b[A\n",
            " 61% 17/28 [00:04<00:03,  2.86it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.21it/s]\n",
            "[18:09:16] DeepAR.Eval: - Full test metrics: ND: 0.022; RMSE: 0.059; test_loss: 1.633\n",
            "[18:09:16] DeepAR.Train: train_loss: -3.1168365478515625\n",
            "100% 2078/2078 [02:01<00:00, 17.04it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.66it/s]\n",
            "[18:09:24] DeepAR.Eval: - Full test metrics: ND: 0.029; RMSE: 0.080; test_loss: 1.556\n",
            "[18:09:24] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_36.pth.tar\n",
            "[18:09:24] DeepAR.Train: Current Best ND is: 0.02263\n",
            "[18:09:25] DeepAR.Train: Epoch 38/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  7% 2/28 [00:00<00:01, 18.43it/s]\u001b[A\n",
            " 32% 9/28 [00:00<00:00, 23.64it/s]\u001b[A\n",
            " 61% 17/28 [00:00<00:00, 29.83it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.53it/s]\n",
            "[18:09:29] DeepAR.Eval: - Full test metrics: ND: 0.028; RMSE: 0.076; test_loss: 1.556\n",
            "[18:09:29] DeepAR.Train: train_loss: -2.895561854044596\n",
            "[18:09:29] DeepAR.Train: train_loss: -2.895561854044596\n",
            " 48% 998/2078 [00:55<00:48, 22.47it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  7% 2/28 [00:00<00:01, 18.34it/s]\u001b[A\n",
            " 39% 11/28 [00:00<00:00, 23.89it/s]\u001b[A\n",
            " 50% 14/28 [00:03<00:05,  2.59it/s]\u001b[A\n",
            "100% 28/28 [00:03<00:00,  7.03it/s]\n",
            "[18:10:24] DeepAR.Eval: - Full test metrics: ND: 0.024; RMSE: 0.061; test_loss: 1.765\n",
            "[18:10:24] DeepAR.Train: train_loss: -2.965905507405599\n",
            " 96% 1999/2078 [01:51<00:04, 18.40it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  8.20it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:01, 11.14it/s]\u001b[A\n",
            " 50% 14/28 [00:00<00:00, 14.73it/s]\u001b[A\n",
            " 68% 19/28 [00:04<00:02,  3.43it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.17it/s]\n",
            "[18:11:21] DeepAR.Eval: - Full test metrics: ND: 0.037; RMSE: 0.115; test_loss: 1.569\n",
            "[18:11:21] DeepAR.Train: train_loss: -2.504089832305908\n",
            "100% 2078/2078 [02:00<00:00, 17.29it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.41it/s]\n",
            "[18:11:30] DeepAR.Eval: - Full test metrics: ND: 0.023; RMSE: 0.064; test_loss: 1.543\n",
            "[18:11:30] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_37.pth.tar\n",
            "[18:11:30] DeepAR.Train: Current Best ND is: 0.02263\n",
            "[18:11:30] DeepAR.Train: Epoch 39/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  7% 2/28 [00:00<00:01, 16.72it/s]\u001b[A\n",
            " 25% 7/28 [00:04<00:06,  3.49it/s]\u001b[A\n",
            " 54% 15/28 [00:04<00:02,  4.89it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.23it/s]\n",
            "[18:11:35] DeepAR.Eval: - Full test metrics: ND: 0.023; RMSE: 0.061; test_loss: 1.546\n",
            "[18:11:35] DeepAR.Train: train_loss: -3.1986605326334634\n",
            "[18:11:35] DeepAR.Train: train_loss: -3.1986605326334634\n",
            " 48% 1000/2078 [00:57<00:58, 18.52it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  7.72it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:01, 10.50it/s]\u001b[A\n",
            " 57% 16/28 [00:00<00:00, 14.06it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.45it/s]\n",
            "[18:12:32] DeepAR.Eval: - Full test metrics: ND: 0.023; RMSE: 0.057; test_loss: 1.589\n",
            "[18:12:32] DeepAR.Train: train_loss: -3.0567525227864585\n",
            " 96% 1999/2078 [01:54<00:03, 22.34it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  7% 2/28 [00:00<00:01, 18.58it/s]\u001b[A\n",
            " 36% 10/28 [00:00<00:00, 24.12it/s]\u001b[A\n",
            " 64% 18/28 [00:00<00:00, 30.07it/s]\u001b[A\n",
            "100% 28/28 [00:03<00:00,  7.05it/s]\n",
            "[18:13:28] DeepAR.Eval: - Full test metrics: ND: 0.029; RMSE: 0.082; test_loss: 1.513\n",
            "[18:13:28] DeepAR.Train: train_loss: -2.77845827738444\n",
            "100% 2078/2078 [02:01<00:00, 17.04it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.27it/s]\n",
            "[18:13:36] DeepAR.Eval: - Full test metrics: ND: 0.027; RMSE: 0.070; test_loss: 1.539\n",
            "[18:13:37] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_38.pth.tar\n",
            "[18:13:37] DeepAR.Train: Current Best ND is: 0.02263\n",
            "[18:13:37] DeepAR.Train: Epoch 40/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:14,  1.82it/s]\u001b[A\n",
            " 14% 4/28 [00:00<00:09,  2.46it/s]\u001b[A\n",
            " 39% 11/28 [00:00<00:04,  3.45it/s]\u001b[A\n",
            " 64% 18/28 [00:00<00:02,  4.83it/s]\u001b[A\n",
            "100% 28/28 [00:05<00:00,  5.45it/s]\n",
            "[18:13:42] DeepAR.Eval: - Full test metrics: ND: 0.027; RMSE: 0.071; test_loss: 1.535\n",
            "[18:13:42] DeepAR.Train: train_loss: -3.3791090647379556\n",
            "[18:13:42] DeepAR.Train: train_loss: -3.3791090647379556\n",
            " 48% 999/2078 [00:57<00:52, 20.70it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  8.32it/s]\u001b[A\n",
            " 32% 9/28 [00:00<00:01, 11.35it/s]\u001b[A\n",
            " 64% 18/28 [00:00<00:00, 15.30it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.90it/s]\n",
            "[18:14:39] DeepAR.Eval: - Full test metrics: ND: 0.030; RMSE: 0.086; test_loss: 1.558\n",
            "[18:14:39] DeepAR.Train: train_loss: -2.589667320251465\n",
            " 96% 1999/2078 [01:53<00:04, 18.59it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  8.01it/s]\u001b[A\n",
            " 25% 7/28 [00:00<00:01, 10.79it/s]\u001b[A\n",
            " 54% 15/28 [00:00<00:00, 14.51it/s]\u001b[A\n",
            " 82% 23/28 [00:00<00:00, 19.09it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.42it/s]\n",
            "[18:15:35] DeepAR.Eval: - Full test metrics: ND: 0.024; RMSE: 0.059; test_loss: 1.535\n",
            "[18:15:35] DeepAR.Train: train_loss: -3.087978998819987\n",
            "100% 2078/2078 [02:01<00:00, 17.10it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.68it/s]\n",
            "[18:15:43] DeepAR.Eval: - Full test metrics: ND: 0.028; RMSE: 0.075; test_loss: 1.687\n",
            "[18:15:43] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_39.pth.tar\n",
            "[18:15:43] DeepAR.Train: Current Best ND is: 0.02263\n",
            "[18:15:43] DeepAR.Train: Epoch 41/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  7% 2/28 [00:00<00:01, 18.80it/s]\u001b[A\n",
            " 39% 11/28 [00:00<00:00, 24.44it/s]\u001b[A\n",
            " 64% 18/28 [00:04<00:01,  5.02it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.43it/s]\n",
            "[18:15:48] DeepAR.Eval: - Full test metrics: ND: 0.026; RMSE: 0.068; test_loss: 1.694\n",
            "[18:15:48] DeepAR.Train: train_loss: -3.419194539388021\n",
            "[18:15:48] DeepAR.Train: train_loss: -3.419194539388021\n",
            " 48% 1000/2078 [00:56<00:46, 23.34it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  7% 2/28 [00:00<00:01, 17.79it/s]\u001b[A\n",
            " 39% 11/28 [00:00<00:00, 23.08it/s]\u001b[A\n",
            " 64% 18/28 [00:00<00:00, 28.79it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.72it/s]\n",
            "[18:16:44] DeepAR.Eval: - Full test metrics: ND: 0.029; RMSE: 0.086; test_loss: 1.504\n",
            "[18:16:44] DeepAR.Train: train_loss: -3.3354714711507163\n",
            " 96% 2000/2078 [01:53<00:04, 18.88it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  7.66it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:01, 10.39it/s]\u001b[A\n",
            " 54% 15/28 [00:00<00:00, 13.90it/s]\u001b[A\n",
            " 79% 22/28 [00:00<00:00, 18.25it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.70it/s]\n",
            "[18:17:41] DeepAR.Eval: - Full test metrics: ND: 0.028; RMSE: 0.083; test_loss: 1.742\n",
            "[18:17:41] DeepAR.Train: train_loss: -4.081197738647461\n",
            "100% 2078/2078 [02:02<00:00, 16.98it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  5.99it/s]\n",
            "[18:17:50] DeepAR.Eval: - Full test metrics: ND: 0.024; RMSE: 0.062; test_loss: 1.514\n",
            "[18:17:51] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_40.pth.tar\n",
            "[18:17:51] DeepAR.Train: Current Best ND is: 0.02263\n",
            "[18:17:51] DeepAR.Train: Epoch 42/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:02,  9.36it/s]\u001b[A\n",
            " 14% 4/28 [00:04<00:11,  2.12it/s]\u001b[A\n",
            " 50% 14/28 [00:04<00:04,  3.00it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.39it/s]\n",
            "[18:17:55] DeepAR.Eval: - Full test metrics: ND: 0.024; RMSE: 0.061; test_loss: 1.535\n",
            "[18:17:55] DeepAR.Train: train_loss: -3.346602439880371\n",
            "[18:17:55] DeepAR.Train: train_loss: -3.346602439880371\n",
            " 48% 999/2078 [00:56<00:59, 18.11it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:02,  9.04it/s]\u001b[A\n",
            " 25% 7/28 [00:00<00:01, 12.10it/s]\u001b[A\n",
            " 50% 14/28 [00:04<00:03,  4.33it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.25it/s]\n",
            "[18:18:52] DeepAR.Eval: - Full test metrics: ND: 0.032; RMSE: 0.100; test_loss: 1.549\n",
            "[18:18:52] DeepAR.Train: train_loss: -2.5973032315572104\n",
            " 96% 1998/2078 [01:53<00:03, 23.08it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  7% 2/28 [00:00<00:01, 18.28it/s]\u001b[A\n",
            " 32% 9/28 [00:03<00:03,  5.14it/s]\u001b[A\n",
            " 64% 18/28 [00:03<00:01,  7.16it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.98it/s]\n",
            "[18:19:48] DeepAR.Eval: - Full test metrics: ND: 0.022; RMSE: 0.056; test_loss: 1.555\n",
            "[18:19:48] DeepAR.Train: train_loss: -3.130016644795736\n",
            "100% 2078/2078 [02:01<00:00, 17.14it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.42it/s]\n",
            "[18:19:57] DeepAR.Eval: - Full test metrics: ND: 0.029; RMSE: 0.081; test_loss: 1.511\n",
            "[18:19:57] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_41.pth.tar\n",
            "[18:19:57] DeepAR.Train: Current Best ND is: 0.02263\n",
            "[18:19:57] DeepAR.Train: Epoch 43/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  7% 2/28 [00:00<00:01, 18.56it/s]\u001b[A\n",
            " 25% 7/28 [00:03<00:05,  3.69it/s]\u001b[A\n",
            " 57% 16/28 [00:04<00:02,  5.18it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.55it/s]\n",
            "[18:20:01] DeepAR.Eval: - Full test metrics: ND: 0.030; RMSE: 0.084; test_loss: 1.508\n",
            "[18:20:01] DeepAR.Train: train_loss: -2.989635467529297\n",
            "[18:20:01] DeepAR.Train: train_loss: -2.989635467529297\n",
            " 48% 999/2078 [00:56<01:00, 17.85it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  8.97it/s]\u001b[A\n",
            " 25% 7/28 [00:00<00:01, 12.00it/s]\u001b[A\n",
            " 54% 15/28 [00:00<00:00, 16.07it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.88it/s]\n",
            "[18:20:58] DeepAR.Eval: - Full test metrics: ND: 0.028; RMSE: 0.088; test_loss: 1.516\n",
            "[18:20:58] DeepAR.Train: train_loss: -3.813782056172689\n",
            " 96% 1998/2078 [01:54<00:03, 22.19it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  7.98it/s]\u001b[A\n",
            " 25% 7/28 [00:00<00:01, 10.76it/s]\u001b[A\n",
            " 50% 14/28 [00:00<00:00, 14.41it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.26it/s]\n",
            "[18:21:56] DeepAR.Eval: - Full test metrics: ND: 0.025; RMSE: 0.067; test_loss: 1.537\n",
            "[18:21:56] DeepAR.Train: train_loss: -3.444634119669596\n",
            "100% 2078/2078 [02:02<00:00, 16.92it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.80it/s]\n",
            "[18:22:04] DeepAR.Eval: - Full test metrics: ND: 0.026; RMSE: 0.070; test_loss: 1.524\n",
            "[18:22:04] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_42.pth.tar\n",
            "[18:22:04] DeepAR.Train: Current Best ND is: 0.02263\n",
            "[18:22:04] DeepAR.Train: Epoch 44/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:03,  6.95it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:02,  9.50it/s]\u001b[A\n",
            " 39% 11/28 [00:03<00:07,  2.23it/s]\u001b[A\n",
            " 68% 19/28 [00:04<00:02,  3.15it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.61it/s]\n",
            "[18:22:09] DeepAR.Eval: - Full test metrics: ND: 0.027; RMSE: 0.075; test_loss: 1.530\n",
            "[18:22:09] DeepAR.Train: train_loss: -2.9933458964029946\n",
            "[18:22:09] DeepAR.Train: train_loss: -2.9933458964029946\n",
            " 48% 999/2078 [00:56<00:47, 22.53it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  7% 2/28 [00:00<00:01, 16.41it/s]\u001b[A\n",
            " 14% 4/28 [00:03<00:14,  1.70it/s]\u001b[A\n",
            " 46% 13/28 [00:03<00:06,  2.40it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.84it/s]\n",
            "[18:23:06] DeepAR.Eval: - Full test metrics: ND: 0.030; RMSE: 0.080; test_loss: 1.505\n",
            "[18:23:06] DeepAR.Train: train_loss: -3.1367292404174805\n",
            " 96% 2000/2078 [01:52<00:04, 18.93it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  8.57it/s]\u001b[A\n",
            " 25% 7/28 [00:00<00:01, 11.48it/s]\u001b[A\n",
            " 32% 9/28 [00:04<00:12,  1.54it/s]\u001b[A\n",
            " 61% 17/28 [00:04<00:05,  2.18it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.33it/s]\n",
            "[18:24:01] DeepAR.Eval: - Full test metrics: ND: 0.030; RMSE: 0.090; test_loss: 1.587\n",
            "[18:24:01] DeepAR.Train: train_loss: -3.2088425954182944\n",
            "100% 2078/2078 [02:00<00:00, 17.28it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.57it/s]\n",
            "[18:24:09] DeepAR.Eval: - Full test metrics: ND: 0.026; RMSE: 0.083; test_loss: 1.566\n",
            "[18:24:09] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_43.pth.tar\n",
            "[18:24:09] DeepAR.Train: Current Best ND is: 0.02263\n",
            "[18:24:10] DeepAR.Train: Epoch 45/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:03,  7.10it/s]\u001b[A\n",
            " 25% 7/28 [00:00<00:02,  9.64it/s]\u001b[A\n",
            " 50% 14/28 [00:00<00:01, 12.97it/s]\u001b[A\n",
            " 68% 19/28 [00:04<00:02,  3.45it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.34it/s]\n",
            "[18:24:14] DeepAR.Eval: - Full test metrics: ND: 0.027; RMSE: 0.084; test_loss: 1.566\n",
            "[18:24:14] DeepAR.Train: train_loss: -3.401482264200846\n",
            "[18:24:14] DeepAR.Train: train_loss: -3.401482264200846\n",
            " 48% 999/2078 [00:55<01:00, 17.93it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  8.58it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:01, 11.57it/s]\u001b[A\n",
            " 50% 14/28 [00:03<00:03,  4.06it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.72it/s]\n",
            "[18:25:09] DeepAR.Eval: - Full test metrics: ND: 0.025; RMSE: 0.065; test_loss: 1.527\n",
            "[18:25:09] DeepAR.Train: train_loss: -2.6708688735961914\n",
            " 96% 2000/2078 [01:51<00:04, 17.36it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  7.38it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:02,  9.97it/s]\u001b[A\n",
            " 36% 10/28 [00:04<00:11,  1.51it/s]\u001b[A\n",
            " 64% 18/28 [00:04<00:04,  2.14it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.32it/s]\n",
            "[18:26:06] DeepAR.Eval: - Full test metrics: ND: 0.031; RMSE: 0.097; test_loss: 1.557\n",
            "[18:26:06] DeepAR.Train: train_loss: -3.34619140625\n",
            "100% 2078/2078 [02:00<00:00, 17.29it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.61it/s]\n",
            "[18:26:14] DeepAR.Eval: - Full test metrics: ND: 0.036; RMSE: 0.106; test_loss: 1.594\n",
            "[18:26:14] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_44.pth.tar\n",
            "[18:26:14] DeepAR.Train: Current Best ND is: 0.02263\n",
            "[18:26:15] DeepAR.Train: Epoch 46/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:03,  8.09it/s]\u001b[A\n",
            " 29% 8/28 [00:03<00:05,  3.96it/s]\u001b[A\n",
            " 61% 17/28 [00:04<00:01,  5.55it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.59it/s]\n",
            "[18:26:19] DeepAR.Eval: - Full test metrics: ND: 0.032; RMSE: 0.092; test_loss: 1.573\n",
            "[18:26:19] DeepAR.Train: train_loss: -3.657648722330729\n",
            "[18:26:19] DeepAR.Train: train_loss: -3.657648722330729\n",
            " 48% 1000/2078 [00:57<00:52, 20.46it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:03<01:44,  3.88s/it]\u001b[A\n",
            " 36% 10/28 [00:03<00:48,  2.72s/it]\u001b[A\n",
            " 68% 19/28 [00:04<00:17,  1.91s/it]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.60it/s]\n",
            "[18:27:16] DeepAR.Eval: - Full test metrics: ND: 0.026; RMSE: 0.070; test_loss: 1.478\n",
            "[18:27:16] DeepAR.Train: train_loss: -3.197449048360189\n",
            " 96% 2000/2078 [01:53<00:04, 19.35it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  6.88it/s]\u001b[A\n",
            " 32% 9/28 [00:00<00:02,  9.45it/s]\u001b[A\n",
            " 43% 12/28 [00:03<00:06,  2.29it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.86it/s]\n",
            "[18:28:12] DeepAR.Eval: - Full test metrics: ND: 0.022; RMSE: 0.058; test_loss: 1.438\n",
            "[18:28:12] DeepAR.Train: train_loss: -3.2820987701416016\n",
            "100% 2078/2078 [02:00<00:00, 17.20it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.84it/s]\n",
            "[18:28:19] DeepAR.Eval: - Full test metrics: ND: 0.021; RMSE: 0.053; test_loss: 1.499\n",
            "[18:28:20] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_45.pth.tar\n",
            "[18:28:20] DeepAR.Utils: Best checkpoint copied to best.pth.tar\n",
            "[18:28:20] DeepAR.Train: - Found new best ND\n",
            "[18:28:20] DeepAR.Train: Current Best ND is: 0.02090\n",
            "[18:28:20] DeepAR.Train: Epoch 47/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:03,  7.34it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:02,  9.99it/s]\u001b[A\n",
            " 57% 16/28 [00:00<00:00, 13.48it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.75it/s]\n",
            "[18:28:25] DeepAR.Eval: - Full test metrics: ND: 0.022; RMSE: 0.056; test_loss: 1.453\n",
            "[18:28:25] DeepAR.Train: train_loss: -2.8657410939534507\n",
            "[18:28:25] DeepAR.Train: train_loss: -2.8657410939534507\n",
            " 48% 998/2078 [00:56<00:46, 23.34it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  7% 2/28 [00:00<00:01, 17.96it/s]\u001b[A\n",
            " 32% 9/28 [00:00<00:00, 23.11it/s]\u001b[A\n",
            " 54% 15/28 [00:04<00:02,  4.44it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.50it/s]\n",
            "[18:29:21] DeepAR.Eval: - Full test metrics: ND: 0.024; RMSE: 0.062; test_loss: 1.468\n",
            "[18:29:21] DeepAR.Train: train_loss: -3.0810333887736\n",
            " 96% 2000/2078 [01:50<00:04, 18.64it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  8.62it/s]\u001b[A\n",
            " 25% 7/28 [00:00<00:01, 11.60it/s]\u001b[A\n",
            " 32% 9/28 [00:04<00:12,  1.56it/s]\u001b[A\n",
            " 64% 18/28 [00:04<00:04,  2.21it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.46it/s]\n",
            "[18:30:15] DeepAR.Eval: - Full test metrics: ND: 0.035; RMSE: 0.107; test_loss: 1.517\n",
            "[18:30:15] DeepAR.Train: train_loss: -3.984318415323893\n",
            "100% 2078/2078 [01:57<00:00, 17.62it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.45it/s]\n",
            "[18:30:23] DeepAR.Eval: - Full test metrics: ND: 0.037; RMSE: 0.112; test_loss: 1.522\n",
            "[18:30:23] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_46.pth.tar\n",
            "[18:30:23] DeepAR.Train: Current Best ND is: 0.02090\n",
            "[18:30:23] DeepAR.Train: Epoch 48/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  7% 2/28 [00:00<00:01, 17.99it/s]\u001b[A\n",
            " 36% 10/28 [00:00<00:00, 23.33it/s]\u001b[A\n",
            " 54% 15/28 [00:04<00:03,  3.77it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.46it/s]\n",
            "[18:30:27] DeepAR.Eval: - Full test metrics: ND: 0.033; RMSE: 0.098; test_loss: 1.473\n",
            "[18:30:27] DeepAR.Train: train_loss: -3.2368882497151694\n",
            "[18:30:27] DeepAR.Train: train_loss: -3.2368882497151694\n",
            " 48% 999/2078 [00:54<00:48, 22.28it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:03<01:45,  3.92s/it]\u001b[A\n",
            " 32% 9/28 [00:04<00:52,  2.75s/it]\u001b[A\n",
            " 61% 17/28 [00:04<00:21,  1.93s/it]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.46it/s]\n",
            "[18:31:22] DeepAR.Eval: - Full test metrics: ND: 0.030; RMSE: 0.085; test_loss: 1.501\n",
            "[18:31:22] DeepAR.Train: train_loss: -3.962207794189453\n",
            " 96% 2000/2078 [01:46<00:04, 18.57it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  8.62it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:01, 11.68it/s]\u001b[A\n",
            " 61% 17/28 [00:00<00:00, 15.74it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.34it/s]\n",
            "[18:32:14] DeepAR.Eval: - Full test metrics: ND: 0.030; RMSE: 0.091; test_loss: 1.422\n",
            "[18:32:14] DeepAR.Train: train_loss: -2.5142757097880044\n",
            "100% 2078/2078 [01:55<00:00, 17.95it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:03<00:00,  7.06it/s]\n",
            "[18:32:23] DeepAR.Eval: - Full test metrics: ND: 0.029; RMSE: 0.094; test_loss: 1.537\n",
            "[18:32:23] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_47.pth.tar\n",
            "[18:32:23] DeepAR.Train: Current Best ND is: 0.02090\n",
            "[18:32:24] DeepAR.Train: Epoch 49/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:00<00:04,  6.67it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:02,  9.12it/s]\u001b[A\n",
            " 50% 14/28 [00:00<00:01, 12.19it/s]\u001b[A\n",
            " 75% 21/28 [00:00<00:00, 16.21it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.34it/s]\n",
            "[18:32:28] DeepAR.Eval: - Full test metrics: ND: 0.033; RMSE: 0.110; test_loss: 1.482\n",
            "[18:32:28] DeepAR.Train: train_loss: -3.6682214736938477\n",
            "[18:32:28] DeepAR.Train: train_loss: -3.6682214736938477\n",
            " 48% 1000/2078 [00:55<00:59, 18.09it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  8.43it/s]\u001b[A\n",
            " 11% 3/28 [00:04<00:16,  1.50it/s]\u001b[A\n",
            " 39% 11/28 [00:04<00:08,  2.12it/s]\u001b[A\n",
            " 68% 19/28 [00:04<00:03,  2.99it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.36it/s]\n",
            "[18:33:23] DeepAR.Eval: - Full test metrics: ND: 0.026; RMSE: 0.065; test_loss: 1.386\n",
            "[18:33:23] DeepAR.Train: train_loss: -3.4300104777018228\n",
            " 96% 1999/2078 [01:48<00:04, 18.16it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  7.63it/s]\u001b[A\n",
            " 25% 7/28 [00:00<00:02, 10.32it/s]\u001b[A\n",
            " 46% 13/28 [00:00<00:01, 13.56it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.19it/s]\n",
            "[18:34:17] DeepAR.Eval: - Full test metrics: ND: 0.031; RMSE: 0.096; test_loss: 1.691\n",
            "[18:34:17] DeepAR.Train: train_loss: -3.4859841664632163\n",
            "100% 2078/2078 [01:57<00:00, 17.74it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.36it/s]\n",
            "[18:34:25] DeepAR.Eval: - Full test metrics: ND: 0.034; RMSE: 0.107; test_loss: 1.705\n",
            "[18:34:25] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_48.pth.tar\n",
            "[18:34:25] DeepAR.Train: Current Best ND is: 0.02090\n",
            "[18:34:26] DeepAR.Train: Epoch 50/50\n",
            "  0% 0/2078 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  7% 2/28 [00:00<00:01, 18.24it/s]\u001b[A\n",
            " 32% 9/28 [00:00<00:00, 23.30it/s]\u001b[A\n",
            " 43% 12/28 [00:04<00:06,  2.43it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.62it/s]\n",
            "[18:34:30] DeepAR.Eval: - Full test metrics: ND: 0.032; RMSE: 0.099; test_loss: 1.690\n",
            "[18:34:30] DeepAR.Train: train_loss: -3.894476572672526\n",
            "[18:34:30] DeepAR.Train: train_loss: -3.894476572672526\n",
            " 48% 999/2078 [00:50<00:58, 18.55it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  4% 1/28 [00:00<00:03,  7.86it/s]\u001b[A\n",
            " 29% 8/28 [00:00<00:01, 10.68it/s]\u001b[A\n",
            " 43% 12/28 [00:04<00:05,  2.81it/s]\u001b[A\n",
            "100% 28/28 [00:04<00:00,  6.49it/s]\n",
            "[18:35:21] DeepAR.Eval: - Full test metrics: ND: 0.031; RMSE: 0.090; test_loss: 1.600\n",
            "[18:35:21] DeepAR.Train: train_loss: -3.6319042841593423\n",
            " 96% 1998/2078 [01:42<00:03, 23.22it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  7% 2/28 [00:00<00:01, 15.77it/s]\u001b[A\n",
            " 39% 11/28 [00:00<00:00, 20.94it/s]\u001b[A\n",
            " 64% 18/28 [00:03<00:01,  5.42it/s]\u001b[A\n",
            "100% 28/28 [00:03<00:00,  7.16it/s]\n",
            "[18:36:13] DeepAR.Eval: - Full test metrics: ND: 0.021; RMSE: 0.057; test_loss: 1.905\n",
            "[18:36:13] DeepAR.Train: train_loss: -2.700346310933431\n",
            "100% 2078/2078 [01:51<00:00, 18.72it/s]\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100% 28/28 [00:04<00:00,  6.08it/s]\n",
            "[18:36:21] DeepAR.Eval: - Full test metrics: ND: 0.029; RMSE: 0.077; test_loss: 1.573\n",
            "[18:36:22] DeepAR.Utils: Checkpoint saved to experiments/base_model/epoch_49.pth.tar\n",
            "[18:36:22] DeepAR.Train: Current Best ND is: 0.02090\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbcC459HiZeb",
        "outputId": "32894b88-1533-4fa0-91f7-a91dafc511dd"
      },
      "source": [
        "!python3 evaluate.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PARAMETERS: {'learning_rate': 0.001, 'batch_size': 4, 'lstm_layers': 5, 'num_epochs': 50, 'train_window': 12, 'test_window': 12, 'predict_start': 8, 'test_predict_start': 8, 'predict_steps': 4, 'num_class': 277, 'cov_dim': 554, 'lstm_hidden_dim': 40, 'embedding_dim': 20, 'sample_times': 12, 'lstm_dropout': 0.3, 'predict_batch': 10}\n",
            "[18:46:08] DeepAR.Eval: Not using cuda...\n",
            "[18:46:08] DeepAR.Eval: Loading the datasets...\n",
            "[18:46:08] DeepAR.Data: test_len: 277\n",
            "[18:46:08] DeepAR.Data: building datasets from data/elect...\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "[18:46:08] DeepAR.Eval: - done.\n",
            "model:  Net(\n",
            "  (embedding): Embedding(277, 20)\n",
            "  (lstm): LSTM(575, 40, num_layers=5, dropout=0.3)\n",
            "  (relu): ReLU()\n",
            "  (distribution_mu): Linear(in_features=200, out_features=1, bias=True)\n",
            "  (distribution_presigma): Linear(in_features=200, out_features=1, bias=True)\n",
            "  (distribution_sigma): Softplus(beta=1, threshold=20)\n",
            ")\n",
            "[18:46:08] DeepAR.Eval: Starting evaluation\n",
            "100% 28/28 [00:04<00:00,  6.86it/s]\n",
            "[18:46:13] DeepAR.Eval: - Full test metrics: ND: 0.021; RMSE: 0.053; test_loss: 1.499\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}